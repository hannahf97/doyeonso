#!/usr/bin/env python3
"""
ìžë™ íŒŒì¼ ì²˜ë¦¬ ìœ í‹¸ë¦¬í‹°
ì—…ë¡œë“œëœ íŒŒì¼ì„ OCR ì²˜ë¦¬í•˜ê³  í†µí•© JSONìœ¼ë¡œ ë³€í™˜í•œ í›„ ë°ì´í„°ë² ì´ìŠ¤ì— ì €ìž¥
"""

import os
import json
import uuid
import re
from datetime import datetime
from typing import Dict, Any, Tuple, Optional
from PIL import Image
from pdf2image import convert_from_bytes
from io import BytesIO

from utils.naver_ocr import process_image_with_ocr
from services.merge_json import merge_ocr_and_detection_results
from config.database_config import get_db_connection
from config.user_config import USER_NAME

def clean_filename(filename: str) -> str:
    """
    íŒŒì¼ëª…ì„ ì •ë¦¬í•˜ëŠ” í•¨ìˆ˜
    - í™•ìž¥ìž ì œê±° (.pdf, .png ë“±)
    - ëì— ìžˆëŠ” ìˆ«ìž ì œê±° (ì˜ˆ: stream_does_ai_1 -> stream_does_ai, ë„ë©´ì˜ˆì‹œ1 -> ë„ë©´ì˜ˆì‹œ)
    
    Args:
        filename: ì›ë³¸ íŒŒì¼ëª…
    
    Returns:
        str: ì •ë¦¬ëœ íŒŒì¼ëª…
    """
    # í™•ìž¥ìž ì œê±°
    base_name = os.path.splitext(filename)[0]
    
    # ëì— ìžˆëŠ” ìˆ«ìž ì œê±° (ì–¸ë”ìŠ¤ì½”ì–´ ìœ ë¬´ ê´€ê³„ì—†ì´)
    # íŒ¨í„´: _ìˆ«ìž ë˜ëŠ” ê·¸ëƒ¥ ìˆ«ìž
    cleaned_name = re.sub(r'_?\d+$', '', base_name)
    
    return cleaned_name

def get_next_testsum_sequence() -> int:
    """ë‹¤ìŒ testsum ì‹œí€€ìŠ¤ ë²ˆí˜¸ë¥¼ ë°˜í™˜"""
    merged_dir = 'uploads/merged_results'
    if not os.path.exists(merged_dir):
        return 1
    
    existing_files = [f for f in os.listdir(merged_dir) if f.startswith('testsum') and f.endswith('.json')]
    if not existing_files:
        return 1
    
    # ì‹œí€€ìŠ¤ ë²ˆí˜¸ ì¶”ì¶œí•˜ì—¬ ìµœëŒ€ê°’ + 1 ë°˜í™˜
    sequences = []
    for filename in existing_files:
        try:
            seq_str = filename.replace('testsum', '').replace('.json', '')
            sequences.append(int(seq_str))
        except ValueError:
            continue
    
    return max(sequences) + 1 if sequences else 1

def extract_image_dimensions(image_path: str) -> Tuple[int, int]:
    """ì´ë¯¸ì§€ì—ì„œ width, height ì¶”ì¶œ"""
    try:
        with Image.open(image_path) as img:
            return img.size  # (width, height)
    except Exception as e:
        print(f"ì´ë¯¸ì§€ í¬ê¸° ì¶”ì¶œ ì˜¤ë¥˜: {e}")
        return 1684, 1190  # ê¸°ë³¸ê°’

def convert_uploaded_file_to_images(file_bytes: bytes, original_filename: str) -> Dict[str, Any]:
    """ì—…ë¡œë“œëœ íŒŒì¼ì„ PNG ì´ë¯¸ì§€ë¡œ ë³€í™˜ (ë™ì¼ íŒŒì¼ëª… ì‹œ ë®ì–´ì“°ê¸°)"""
    
    result = {
        'success': False,
        'converted_images': [],
        'error_message': None,
        'updated_files': []
    }
    
    try:
        # ì—…ë¡œë“œ ë””ë ‰í† ë¦¬ ìƒì„±
        upload_dir = 'uploads/uploaded_images'
        if not os.path.exists(upload_dir):
            os.makedirs(upload_dir)
        
        file_extension = original_filename.lower().split('.')[-1]
        # íŒŒì¼ëª…ì—ì„œ í™•ìž¥ìžë§Œ ì œê±° (ìˆ«ìžë‚˜ _ ì œê±°í•˜ì§€ ì•ŠìŒ)
        base_filename = os.path.splitext(original_filename)[0]
        
        if file_extension == 'pdf':
            # PDF ì²˜ë¦¬
            try:
                images = convert_from_bytes(file_bytes, dpi=300)
                for i, image in enumerate(images):
                    if len(images) > 1:
                        filename = f"{base_filename}_page_{i+1}.png"
                    else:
                        filename = f"{base_filename}.png"
                    
                    save_path = os.path.join(upload_dir, filename)
                    
                    # ê¸°ì¡´ íŒŒì¼ì´ ìžˆìœ¼ë©´ ì—…ë°ì´íŠ¸ í‘œì‹œ
                    if os.path.exists(save_path):
                        result['updated_files'].append(save_path)
                        print(f"ðŸ”„ ê¸°ì¡´ íŒŒì¼ ì—…ë°ì´íŠ¸: {filename}")
                    
                    image.save(save_path, 'PNG')
                    result['converted_images'].append(save_path)
                
                result['success'] = True
                
            except Exception as e:
                result['error_message'] = f"PDF ë³€í™˜ ì˜¤ë¥˜: {str(e)}"
                
        else:
            # ì´ë¯¸ì§€ íŒŒì¼ ì²˜ë¦¬
            try:
                image = Image.open(BytesIO(file_bytes))
                
                # RGBë¡œ ë³€í™˜
                if image.mode != 'RGB':
                    image = image.convert('RGB')
                
                filename = f"{base_filename}.png"
                save_path = os.path.join(upload_dir, filename)
                
                # ê¸°ì¡´ íŒŒì¼ì´ ìžˆìœ¼ë©´ ì—…ë°ì´íŠ¸ í‘œì‹œ
                if os.path.exists(save_path):
                    result['updated_files'].append(save_path)
                    print(f"ðŸ”„ ê¸°ì¡´ íŒŒì¼ ì—…ë°ì´íŠ¸: {filename}")
                
                image.save(save_path, 'PNG')
                result['converted_images'].append(save_path)
                result['success'] = True
                
            except Exception as e:
                result['error_message'] = f"ì´ë¯¸ì§€ ë³€í™˜ ì˜¤ë¥˜: {str(e)}"
    
    except Exception as e:
        result['error_message'] = f"íŒŒì¼ ì²˜ë¦¬ ì˜¤ë¥˜: {str(e)}"
    
    return result

def create_integrated_json(image_path: str, ocr_result: Dict, original_filename: str) -> Dict[str, Any]:
    """OCRê³¼ Detection ê²°ê³¼ë¥¼ í†µí•©í•˜ì—¬ testsum{seq}.json ìƒì„± (íŒŒì¼ëª… ë§¤í•‘ ë°©ì‹)"""
    
    result = {
        'success': False,
        'merged_path': None,
        'error_message': None,
        'sequence': None
    }
    
    try:
        # íŒŒì¼ëª…ì—ì„œ í™•ìž¥ìžë§Œ ì œê±° (ìˆ«ìžë‚˜ _ ì œê±°í•˜ì§€ ì•ŠìŒ)
        base_filename = os.path.splitext(original_filename)[0]
        
        # Detection ê²°ê³¼ íŒŒì¼ë“¤ì„ íŒŒì¼ëª…ìœ¼ë¡œ ë§¤í•‘í•˜ì—¬ ë¡œë“œ
        detection_dir = 'uploads/detection_results'
        detection_data = None
        matched_detection_files = []
        
        if os.path.exists(detection_dir):
            # detection_results í´ë”ì˜ ëª¨ë“  JSON íŒŒì¼ í™•ì¸
            for detection_file in os.listdir(detection_dir):
                if detection_file.endswith('.json'):
                    detection_base = os.path.splitext(detection_file)[0]
                    
                    # íŒŒì¼ëª…ì´ ì¼ì¹˜í•˜ëŠ” ê²½ìš° (ëŒ€ì†Œë¬¸ìž ë¬´ì‹œ, í™•ìž¥ìžë§Œ ì œê±°í•´ì„œ ë¹„êµ)
                    if detection_base.lower() == base_filename.lower():
                        detection_path = os.path.join(detection_dir, detection_file)
                        try:
                            with open(detection_path, 'r', encoding='utf-8') as f:
                                file_detection_data = json.load(f)
                            matched_detection_files.append({
                                'filename': detection_file,
                                'data': file_detection_data
                            })
                        except Exception as e:
                            print(f"Detection íŒŒì¼ ë¡œë“œ ì˜¤ë¥˜ ({detection_file}): {e}")
        
        # ë§¤ì¹­ëœ detection íŒŒì¼ë“¤ì„ í•˜ë‚˜ë¡œ í†µí•©
        if matched_detection_files:
            if len(matched_detection_files) == 1:
                detection_data = matched_detection_files[0]['data']
            else:
                # ì—¬ëŸ¬ detection íŒŒì¼ì´ ìžˆëŠ” ê²½ìš° í†µí•©
                detection_data = {
                    "merged_detections": True,
                    "source_files": [f['filename'] for f in matched_detection_files],
                    "detections": []
                }
                for detection_file in matched_detection_files:
                    if 'detections' in detection_file['data']:
                        detection_data['detections'].extend(detection_file['data']['detections'])
                    # ë‹¤ë¥¸ í•„ë“œë“¤ë„ ë³‘í•©
                    for key, value in detection_file['data'].items():
                        if key not in detection_data and key != 'detections':
                            detection_data[key] = value
        else:
            print(f"ê²½ê³ : '{base_filename}'ê³¼ ë§¤ì¹­ë˜ëŠ” detection íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
        
        # ì´ë¯¸ì§€ í¬ê¸° ì •ë³´ ì¶”ì¶œ
        width, height = extract_image_dimensions(image_path)
        
        # Detection ë°ì´í„°ì—ì„œ í¬ê¸° ì •ë³´ ì—…ë°ì´íŠ¸ (ìžˆëŠ” ê²½ìš°)
        if detection_data and 'image_info' in detection_data:
            width = detection_data['image_info'].get('width', width)
            height = detection_data['image_info'].get('height', height)
        
        # OCR ë°ì´í„°ì—ì„œ í¬ê¸° ì •ë³´ ì¶”ì¶œ ì‹œë„
        if ocr_result and 'images' in ocr_result:
            for img_data in ocr_result['images']:
                if 'width' in img_data and 'height' in img_data:
                    width = img_data['width']
                    height = img_data['height']
                    break
        
        # ì‹œí€€ìŠ¤ ë²ˆí˜¸ ìƒì„±
        sequence = get_next_testsum_sequence()
        
        # ì €ìž¥í•  íŒŒì¼ëª…ì€ base_filename ì‚¬ìš© (í™•ìž¥ìžë§Œ ì œê±°)
        clean_filename_for_save = base_filename
        
        # í†µí•© JSON êµ¬ì¡° ìƒì„± (ì¤‘ì²© êµ¬ì¡°)
        integrated_data = {}
        
        # 1. OCR ë°ì´í„°ë¥¼ "ocr" ê°ì²´ ì•ˆì— ë°°ì¹˜
        if ocr_result:
            integrated_data["ocr"] = {
                "label": "ocr",
                **ocr_result
            }
        
        # 2. Detection ë°ì´í„°ë¥¼ "detecting" ê°ì²´ ì•ˆì— ë°°ì¹˜
        if detection_data:
            integrated_data["detecting"] = detection_data
        
        # 3. ë©”íƒ€ë°ì´í„°ëŠ” ìµœìƒìœ„ ë ˆë²¨ì— ì¶”ê°€
        integrated_data.update({
            "source_filename": original_filename,
            "base_filename": base_filename,
            "clean_filename_for_save": clean_filename_for_save,
            "created_at": datetime.now().isoformat(),
            "width": width,
            "height": height,
            "file_mapping": {
                "matched_detection_files": len(matched_detection_files),
                "detection_sources": [f['filename'] for f in matched_detection_files] if matched_detection_files else []
            }
        })
        
        # merged_results ë””ë ‰í† ë¦¬ ìƒì„±
        merged_dir = 'uploads/merged_results'
        if not os.path.exists(merged_dir):
            os.makedirs(merged_dir)
        
        # clean_filename_for_saveë¥¼ ì‚¬ìš©í•˜ì—¬ íŒŒì¼ëª… ìƒì„± (_merged ì—†ì´)
        merged_filename = f"{clean_filename_for_save}.json"
        merged_path = os.path.join(merged_dir, merged_filename)
        
        # ê¸°ì¡´ íŒŒì¼ì´ ìžˆìœ¼ë©´ ì—…ë°ì´íŠ¸ í‘œì‹œ
        if os.path.exists(merged_path):
            print(f"ðŸ”„ ê¸°ì¡´ í†µí•© JSON ì—…ë°ì´íŠ¸: {merged_filename}")
        
        with open(merged_path, 'w', encoding='utf-8') as f:
            json.dump(integrated_data, f, ensure_ascii=False, indent=2)
        
        result.update({
            'success': True,
            'merged_path': merged_path,
            'sequence': sequence,
            'integrated_data': integrated_data
        })
        
    except Exception as e:
        result['error_message'] = f"í†µí•© JSON ìƒì„± ì˜¤ë¥˜: {str(e)}"
    
    return result

def save_to_database(integrated_data: Dict, image_path: str, original_filename: str) -> Dict[str, Any]:
    """í†µí•© ë°ì´í„°ë¥¼ PostgreSQL ë°ì´í„°ë² ì´ìŠ¤ì— ì €ìž¥ (ë™ì¼ íŒŒì¼ëª… ì‹œ ì—…ë°ì´íŠ¸)"""
    
    result = {
        'success': False,
        'db_id': None,
        'error_message': None,
        'is_update': False
    }
    
    try:
        conn = get_db_connection()
        if not conn:
            result['error_message'] = "ë°ì´í„°ë² ì´ìŠ¤ ì—°ê²° ì‹¤íŒ¨"
            return result
        
        cursor = conn.cursor()
        
        # ë°ì´í„°ë² ì´ìŠ¤ì— ì €ìž¥í•  ë•ŒëŠ” í™•ìž¥ìžì™€ ë’¤ì˜ ìˆ«ìžë“¤ì„ ì œê±°í•œ íŒŒì¼ëª… ì‚¬ìš©
        base_filename = os.path.splitext(original_filename)[0]
        # íŒŒì¼ëª… ë’¤ì˜ _ìˆ«ìž, ìˆ«ìž íŒ¨í„´ ì œê±° (ì˜ˆ: stream_dose_ai_1 -> stream_dose_ai, ë„ë©´ì˜ˆì‹œ1 -> ë„ë©´ì˜ˆì‹œ)
        base_filename = clean_filename(base_filename)
        
        # ê¸°ì¡´ ë ˆì½”ë“œ í™•ì¸
        check_query = """
        SELECT d_id FROM domyun WHERE d_name = %s AND "user" = %s;
        """
        cursor.execute(check_query, (base_filename, USER_NAME))
        existing_record = cursor.fetchone()
        
        if existing_record:
            # ê¸°ì¡´ ë ˆì½”ë“œ ì—…ë°ì´íŠ¸
            update_query = """
            UPDATE domyun 
            SET create_date = %s, json_data = %s, image_path = %s
            WHERE d_id = %s
            RETURNING d_id;
            """
            cursor.execute(update_query, (
                datetime.now(),
                json.dumps(integrated_data, ensure_ascii=False),
                image_path,
                existing_record[0]
            ))
            db_id = cursor.fetchone()[0]
            result['is_update'] = True
            print(f"ðŸ”„ ê¸°ì¡´ ë°ì´í„°ë² ì´ìŠ¤ ë ˆì½”ë“œ ì—…ë°ì´íŠ¸: ID {db_id}")
        else:
            # ìƒˆ ë ˆì½”ë“œ ì‚½ìž…
            insert_query = """
            INSERT INTO domyun (d_name, "user", create_date, json_data, image_path)
            VALUES (%s, %s, %s, %s, %s)
            RETURNING d_id;
            """
            cursor.execute(insert_query, (
                base_filename,
                USER_NAME,
                datetime.now(),
                json.dumps(integrated_data, ensure_ascii=False),
                image_path
            ))
            db_id = cursor.fetchone()[0]
            print(f"âœ… ìƒˆ ë°ì´í„°ë² ì´ìŠ¤ ë ˆì½”ë“œ ìƒì„±: ID {db_id}")
        
        conn.commit()
        cursor.close()
        conn.close()
        
        result.update({
            'success': True,
            'db_id': db_id
        })
        
    except Exception as e:
        result['error_message'] = f"ë°ì´í„°ë² ì´ìŠ¤ ì €ìž¥ ì˜¤ë¥˜: {str(e)}"
        if 'conn' in locals():
            conn.rollback()
            conn.close()
    
    return result

def process_uploaded_file_auto(file_bytes: bytes, original_filename: str) -> Dict[str, Any]:
    """ì™„ì „ ìžë™í™”ëœ íŒŒì¼ ì²˜ë¦¬ ì›Œí¬í”Œë¡œìš°"""
    
    workflow_result = {
        'success': False,
        'steps_completed': [],
        'total_steps': 6,
        'results': {},
        'error_message': None,
        'rollback_info': []
    }
    
    try:
        # 1ë‹¨ê³„: ì´ë¯¸ì§€ ë³€í™˜
        workflow_result['steps_completed'].append("ðŸ”„ íŒŒì¼ ë³€í™˜ ì‹œìž‘")
        convert_result = convert_uploaded_file_to_images(file_bytes, original_filename)
        
        if not convert_result['success']:
            workflow_result['error_message'] = convert_result['error_message']
            return workflow_result
        
        workflow_result['steps_completed'].append("âœ… ì´ë¯¸ì§€ ë³€í™˜ ì™„ë£Œ")
        workflow_result['results']['converted_images'] = convert_result['converted_images']
        
        # ê° ë³€í™˜ëœ ì´ë¯¸ì§€ì— ëŒ€í•´ ì²˜ë¦¬
        processed_results = []
        
        for image_path in convert_result['converted_images']:
            image_result = {
                'image_path': image_path,
                'ocr_result': None,
                'integrated_result': None,
                'db_result': None
            }
            
            # 2ë‹¨ê³„: OCR ì²˜ë¦¬
            workflow_result['steps_completed'].append(f"ðŸ” OCR ì²˜ë¦¬ ì¤‘: {os.path.basename(image_path)}")
            ocr_result = process_image_with_ocr(image_path)
            
            if ocr_result['success']:
                workflow_result['steps_completed'].append(f"âœ… OCR ì™„ë£Œ: {os.path.basename(image_path)}")
                image_result['ocr_result'] = ocr_result
                
                # OCR ë°ì´í„° ë¡œë“œ
                if ocr_result['json_path'] and os.path.exists(ocr_result['json_path']):
                    with open(ocr_result['json_path'], 'r', encoding='utf-8') as f:
                        ocr_data = json.load(f)
                else:
                    ocr_data = None
                
                # 3ë‹¨ê³„: í†µí•© JSON ìƒì„±
                workflow_result['steps_completed'].append(f"ðŸ“Š í†µí•© JSON ìƒì„± ì¤‘: {os.path.basename(image_path)}")
                integrated_result = create_integrated_json(image_path, ocr_data, original_filename)
                
                if integrated_result['success']:
                    workflow_result['steps_completed'].append(f"âœ… í†µí•© JSON ì™„ë£Œ: testsum{integrated_result['sequence']}.json")
                    image_result['integrated_result'] = integrated_result
                    
                    # 4ë‹¨ê³„: ë°ì´í„°ë² ì´ìŠ¤ ì €ìž¥
                    workflow_result['steps_completed'].append(f"ðŸ’¾ ë°ì´í„°ë² ì´ìŠ¤ ì €ìž¥ ì¤‘")
                    db_result = save_to_database(
                        integrated_result['integrated_data'], 
                        image_path, 
                        original_filename
                    )
                    
                    if db_result['success']:
                        workflow_result['steps_completed'].append(f"âœ… DB ì €ìž¥ ì™„ë£Œ: ID {db_result['db_id']}")
                        image_result['db_result'] = db_result
                    else:
                        workflow_result['steps_completed'].append(f"âŒ DB ì €ìž¥ ì‹¤íŒ¨: {db_result['error_message']}")
                        image_result['db_result'] = db_result
                else:
                    workflow_result['steps_completed'].append(f"âŒ í†µí•© JSON ì‹¤íŒ¨: {integrated_result['error_message']}")
                    image_result['integrated_result'] = integrated_result
            else:
                workflow_result['steps_completed'].append(f"âŒ OCR ì‹¤íŒ¨: {ocr_result['error_message']}")
                image_result['ocr_result'] = ocr_result
            
            processed_results.append(image_result)
        
        workflow_result['results']['processed_images'] = processed_results
        workflow_result['success'] = True
        workflow_result['steps_completed'].append("ðŸŽ‰ ëª¨ë“  ì²˜ë¦¬ ì™„ë£Œ!")
        
    except Exception as e:
        workflow_result['error_message'] = f"ì›Œí¬í”Œë¡œìš° ì˜¤ë¥˜: {str(e)}"
        workflow_result['steps_completed'].append(f"âŒ ì²˜ë¦¬ ì¤‘ë‹¨: {str(e)}")
    
    return workflow_result

def get_processing_statistics() -> Dict[str, Any]:
    """ì²˜ë¦¬ í†µê³„ ì •ë³´ ë°˜í™˜"""
    
    stats = {
        'total_files': 0,
        'today_files': 0,
        'total_merged': 0,
        'total_images': 0,
        'success_rate': 0.0
    }
    
    try:
        # ì—…ë¡œë“œëœ ì´ë¯¸ì§€ ìˆ˜
        images_dir = 'uploads/uploaded_images'
        if os.path.exists(images_dir):
            stats['total_images'] = len([f for f in os.listdir(images_dir) if f.endswith('.png')])
        
        # ë³‘í•©ëœ ê²°ê³¼ ìˆ˜
        merged_dir = 'uploads/merged_results'
        if os.path.exists(merged_dir):
            merged_files = [f for f in os.listdir(merged_dir) if f.startswith('testsum')]
            stats['total_merged'] = len(merged_files)
            
            # ì˜¤ëŠ˜ ìƒì„±ëœ íŒŒì¼ ìˆ˜
            today = datetime.now().date()
            today_count = 0
            
            for filename in merged_files:
                filepath = os.path.join(merged_dir, filename)
                file_date = datetime.fromtimestamp(os.path.getctime(filepath)).date()
                if file_date == today:
                    today_count += 1
            
            stats['today_files'] = today_count
        
        # ì„±ê³µë¥  ê³„ì‚°
        if stats['total_images'] > 0:
            stats['success_rate'] = (stats['total_merged'] / stats['total_images']) * 100
        
        stats['total_files'] = stats['total_images']
        
    except Exception as e:
        print(f"í†µê³„ ê³„ì‚° ì˜¤ë¥˜: {e}")
    
    return stats 