import streamlit as st
import os
import json
from models.chatbotModel import PIDExpertChatbot
from loguru import logger
import time
from datetime import datetime
from config.database_config import get_db_connection

def show():
    """P&ID ì „ë¬¸ê°€ ì±—ë´‡ í˜ì´ì§€"""
    
    st.title("ğŸ”§ P&ID ë„ë©´ ë¶„ì„ ì „ë¬¸ê°€ ì±—ë´‡")
    st.markdown("---")
    
    # ì±—ë´‡ ì´ˆê¸°í™”
    if 'chatbot' not in st.session_state:
        with st.spinner("ğŸ¤– P&ID ì „ë¬¸ê°€ ì±—ë´‡ì„ ì´ˆê¸°í™”í•˜ëŠ” ì¤‘..."):
            st.session_state.chatbot = PIDExpertChatbot()
    
    # íŒŒì¼ ë¦¬ìŠ¤íŠ¸ì—ì„œ ì„ íƒëœ íŒŒì¼ë“¤ í™•ì¸ ë° í‘œì‹œ
    if 'selected_files_for_chat' in st.session_state and st.session_state.selected_files_for_chat:
        st.markdown("## ğŸ“‹ ì„ íƒëœ íŒŒì¼ë“¤")
        
        selected_files = st.session_state.selected_files_for_chat
        
        col1, col2 = st.columns([3, 1])
        with col1:
            st.success(f"âœ… **{len(selected_files)}ê°œ íŒŒì¼ì´ ì„ íƒë˜ì—ˆìŠµë‹ˆë‹¤**")
            
            # íŒŒì¼ ì •ë³´ë¥¼ ë°ì´í„°ë² ì´ìŠ¤ì—ì„œ ê°€ì ¸ì™€ì„œ í‘œì‹œ
            conn = get_db_connection()
            if conn:
                try:
                    for i, file_info in enumerate(selected_files):
                        with st.expander(f"ğŸ“„ {file_info['name']}", expanded=False):
                            # ë°ì´í„°ë² ì´ìŠ¤ì—ì„œ ìƒì„¸ ì •ë³´ ì¡°íšŒ
                            file_details = get_file_details(conn, file_info['id'])
                            if file_details:
                                col_a, col_b = st.columns(2)
                                with col_a:
                                    st.write(f"**ID:** {file_details['id']}")
                                    st.write(f"**ì‚¬ìš©ì:** {file_details['user']}")
                                    st.write(f"**ë“±ë¡ì¼:** {file_details['create_date']}")
                                
                                with col_b:
                                    # JSON ë°ì´í„°ì—ì„œ OCR/Detection ì •ë³´ ì¶”ì¶œ
                                    if file_details['json_data']:
                                        try:
                                            data = file_details['json_data'] if isinstance(file_details['json_data'], dict) else json.loads(file_details['json_data'])
                                            ocr_count = count_ocr_fields(data)
                                            detection_count = count_detection_objects(data)
                                            
                                            st.write(f"**OCR í•„ë“œ:** {ocr_count}ê°œ")
                                            st.write(f"**Detection ê°ì²´:** {detection_count}ê°œ")
                                        except:
                                            st.write("**OCR í•„ë“œ:** 0ê°œ")
                                            st.write("**Detection ê°ì²´:** 0ê°œ")
                                
                                # OCR í…ìŠ¤íŠ¸ ë¯¸ë¦¬ë³´ê¸°
                                if file_details['json_data']:
                                    ocr_text = extract_ocr_text_preview(file_details['json_data'])
                                    if ocr_text:
                                        st.markdown("**ğŸ“„ OCR í…ìŠ¤íŠ¸ ë¯¸ë¦¬ë³´ê¸°:**")
                                        st.text_area("OCR í…ìŠ¤íŠ¸ ë¯¸ë¦¬ë³´ê¸°", value=ocr_text[:200] + "..." if len(ocr_text) > 200 else ocr_text, height=80, disabled=True, key=f"ocr_preview_{i}", label_visibility="collapsed")
                finally:
                    conn.close()
        
        with col2:
            if st.button("ğŸ—‘ï¸ íŒŒì¼ ì„ íƒ ì´ˆê¸°í™”", use_container_width=True):
                st.session_state.selected_files_for_chat = []
                st.rerun()
        
        st.markdown("---")
        
        # ì„ íƒëœ íŒŒì¼ë“¤ì— ëŒ€í•œ ë¹ ë¥¸ ë¶„ì„ ë²„íŠ¼
        st.markdown("### ğŸš€ ë¹ ë¥¸ ë¶„ì„")
        col_a, col_b, col_c = st.columns(3)
        
        with col_a:
            if st.button("ğŸ“‹ ì „ì²´ íŒŒì¼ ìš”ì•½", use_container_width=True):
                _add_test_question(f"ì„ íƒëœ {len(selected_files)}ê°œ íŒŒì¼({', '.join([f['name'] for f in selected_files])})ì— ëŒ€í•œ ì¢…í•©ì ì¸ ìš”ì•½ì„ ì œê³µí•´ì£¼ì„¸ìš”.")
        
        with col_b:
            if st.button("ğŸ” ìƒì„¸ ë¶„ì„", use_container_width=True):
                _add_test_question(f"ì„ íƒëœ íŒŒì¼ë“¤({', '.join([f['name'] for f in selected_files])})ì˜ ìƒì„¸ ë¶„ì„ì„ í•´ì£¼ì„¸ìš”. ì£¼ìš” ê³„ì¸¡ê¸°ê¸°, ì œì–´ ì‹œìŠ¤í…œ, ì•ˆì „ì¥ì¹˜ë¥¼ ì¤‘ì‹¬ìœ¼ë¡œ ì„¤ëª…í•´ì£¼ì„¸ìš”.")
        
        with col_c:
            if st.button("âš¡ OCR í…ìŠ¤íŠ¸ ë¶„ì„", use_container_width=True):
                _add_test_question(f"ì„ íƒëœ íŒŒì¼ë“¤ì˜ OCR í…ìŠ¤íŠ¸ë¥¼ ë¶„ì„í•˜ì—¬ ì£¼ìš” ì„¤ë¹„ëª…, ê³„ì¸¡ê¸° íƒœê·¸, ì œì–´ í¬ì¸íŠ¸ë¥¼ ì¶”ì¶œí•´ì£¼ì„¸ìš”.")
    
    # ê¸°ì¡´ ë‹¨ì¼ ë„ë©´ ì„ íƒ ê¸°ëŠ¥ (í˜¸í™˜ì„± ìœ ì§€)
    selected_drawing = st.session_state.get('selected_drawing_name', None)
    
    if selected_drawing and not st.session_state.get('selected_files_for_chat'):
        st.success(f"âœ… ì„ íƒëœ ë„ë©´: **{selected_drawing}**")
        st.info("ğŸ’¡ ì´ ë„ë©´ì— ëŒ€í•´ ì§ˆë¬¸í•˜ì‹œë©´ ë°ì´í„°ë² ì´ìŠ¤ì˜ ì •ë³´ë¥¼ í™œìš©í•˜ì—¬ ë‹µë³€í•´ë“œë¦½ë‹ˆë‹¤.")
        
        # ë¹ ë¥¸ ë„ë©´ ìš”ì•½ ë²„íŠ¼
        col1, col2 = st.columns(2)
        with col1:
            if st.button("ğŸ“‹ ì„ íƒëœ ë„ë©´ ìš”ì•½", use_container_width=True):
                with st.spinner("ë„ë©´ ìš”ì•½ ìƒì„± ì¤‘..."):
                    summary_result = st.session_state.chatbot.generate_drawing_summary(
                        selected_drawing, 
                        "latest"
                    )
                    
                    # ìš”ì•½ ê²°ê³¼ë¥¼ ëŒ€í™”ì— ì¶”ê°€
                    if 'messages' not in st.session_state:
                        st.session_state.messages = []
                    
                    st.session_state.messages.append({
                        "role": "assistant",
                        "content": summary_result['response'],
                        "timestamp": datetime.now(),
                        "sources": summary_result.get('sources', []),
                        "debug_info": {
                            "query_type": summary_result.get('query_type'),
                            "context_quality": summary_result.get('context_quality'),
                            "web_search_used": summary_result.get('web_search_used', False)
                        }
                    })
                    
                    st.success("âœ… ìš”ì•½ ì™„ë£Œ!")
                    st.rerun()
        
        with col2:
            if st.button("ğŸ” ë„ë©´ ìƒì„¸ ë¶„ì„", use_container_width=True):
                # ìƒì„¸ ë¶„ì„ ì§ˆë¬¸ì„ ëŒ€í™”ì— ì¶”ê°€
                analysis_prompt = f"'{selected_drawing}' ë„ë©´ì˜ ìƒì„¸ ë¶„ì„ì„ í•´ì£¼ì„¸ìš”. ì£¼ìš” ê³„ì¸¡ê¸°ê¸°, ì œì–´ ì‹œìŠ¤í…œ, ì•ˆì „ì¥ì¹˜ë¥¼ ì¤‘ì‹¬ìœ¼ë¡œ ì„¤ëª…í•´ì£¼ì„¸ìš”."
                
                if 'messages' not in st.session_state:
                    st.session_state.messages = []
                
                # ì‚¬ìš©ì ì§ˆë¬¸ ì¶”ê°€
                st.session_state.messages.append({
                    "role": "user",
                    "content": analysis_prompt,
                    "timestamp": datetime.now()
                })
                
                # ìë™ ì‘ë‹µ ìƒì„±
                with st.spinner("ğŸ¤” ìƒì„¸ ë¶„ì„ ì¤‘..."):
                    response_data = st.session_state.chatbot.generate_response(
                        analysis_prompt,
                        use_web_search=False,
                        selected_drawing=selected_drawing,
                        selected_files=st.session_state.get('selected_files_for_chat')
                    )
                
                # ì–´ì‹œìŠ¤í„´íŠ¸ ë©”ì‹œì§€ ì €ì¥
                st.session_state.messages.append({
                    "role": "assistant",
                    "content": response_data['response'],
                    "timestamp": datetime.now(),
                    "sources": response_data.get('sources', []),
                    "debug_info": {
                        "query_type": response_data.get('query_type'),
                        "context_quality": response_data.get('context_quality'),
                        "web_search_used": response_data.get('web_search_used', False)
                    }
                })
                
                st.success("âœ… ìƒì„¸ ë¶„ì„ ì™„ë£Œ!")
                st.rerun()
    
    # íŒŒì¼ì´ ì„ íƒë˜ì§€ ì•Šì€ ê²½ìš°
    if not selected_drawing and not st.session_state.get('selected_files_for_chat'):
        st.info("ğŸ’¡ ë„ë©´ì„ ì„ íƒí•˜ë ¤ë©´ ğŸ“‹ FILE LIST í˜ì´ì§€ë¡œ ì´ë™í•˜ì„¸ìš”.")
        
        col1, col2, col3 = st.columns([1, 1, 1])
        with col2:
            if st.button("ğŸ“‹ íŒŒì¼ ë¦¬ìŠ¤íŠ¸ë¡œ ì´ë™", use_container_width=True, type="primary"):
                st.session_state['page_view'] = 'filelist'
                st.rerun()

    # í…ŒìŠ¤íŠ¸ìš© ì§ˆë¬¸ ë²„íŠ¼ë“¤
    st.markdown("## ğŸ§ª í…ŒìŠ¤íŠ¸ ì§ˆë¬¸")
    st.markdown("ì•„ë˜ ë²„íŠ¼ì„ í´ë¦­í•˜ì—¬ ë‹¤ì–‘í•œ ì§ˆë¬¸ì„ í…ŒìŠ¤íŠ¸í•´ë³´ì„¸ìš”:")
    
    # ì§ˆë¬¸ ì¹´í…Œê³ ë¦¬ë³„ë¡œ ë²„íŠ¼ ë°°ì¹˜
    col1, col2, col3 = st.columns(3)
    
    with col1:
        st.markdown("### ğŸ”§ ê³„ì¸¡ê¸°ê¸°")
        if st.button("FT-101 ì„¤ëª…", key="test_ft101", use_container_width=True):
            _add_test_question("FT-101 ê³„ì¸¡ê¸°ì˜ ì—­í• ê³¼ ìœ„ì¹˜ë¥¼ ìì„¸íˆ ì„¤ëª…í•´ì£¼ì„¸ìš”.")
        
        if st.button("ì••ë ¥ ì¡°ì ˆ ì‹œìŠ¤í…œ", key="test_pressure", use_container_width=True):
            _add_test_question("ì••ë ¥ ì¡°ì ˆ ì‹œìŠ¤í…œ(PC)ì˜ êµ¬ì„±ê³¼ ì‘ë™ ì›ë¦¬ë¥¼ ì„¤ëª…í•´ì£¼ì„¸ìš”.")
        
        if st.button("ì˜¨ë„ ì œì–´", key="test_temp", use_container_width=True):
            _add_test_question("ì˜¨ë„ ì œì–´ ì‹œìŠ¤í…œ(TC)ì—ì„œ PID ì œì–´ì˜ ì—­í• ì€ ë¬´ì—‡ì¸ê°€ìš”?")
    
    with col2:
        st.markdown("### ğŸ›¡ï¸ ì•ˆì „ ì‹œìŠ¤í…œ")
        if st.button("ë¹„ìƒì •ì§€ ì‹œìŠ¤í…œ", key="test_esd", use_container_width=True):
            _add_test_question("ë¹„ìƒì •ì§€(ESD) ì‹œìŠ¤í…œì˜ êµ¬ì„±ê³¼ ì‘ë™ ìˆœì„œë¥¼ ì„¤ëª…í•´ì£¼ì„¸ìš”.")
        
        if st.button("ì•ˆì „ë°¸ë¸Œ", key="test_safety_valve", use_container_width=True):
            _add_test_question("ì•ˆì „ë°¸ë¸Œ(PSV)ì˜ ì„¤ì •ì••ë ¥ê³¼ ë™ì‘ ì›ë¦¬ë¥¼ ì„¤ëª…í•´ì£¼ì„¸ìš”.")
        
        if st.button("ì¸í„°ë¡ ì‹œìŠ¤í…œ", key="test_interlock", use_container_width=True):
            _add_test_question("ê³µì • ì¸í„°ë¡ ì‹œìŠ¤í…œì˜ ì¢…ë¥˜ì™€ ê°ê°ì˜ ì—­í• ì„ ì„¤ëª…í•´ì£¼ì„¸ìš”.")
    
    with col3:
        st.markdown("### ğŸ“Š ë¶„ì„ ì§ˆë¬¸")
        if st.button("ì œì–´ë£¨í”„ ë¶„ì„", key="test_control_loop", use_container_width=True):
            _add_test_question("ì£¼ìš” ì œì–´ë£¨í”„ë“¤ì˜ ìƒí˜¸ì‘ìš©ê³¼ ìµœì í™” ë°©ì•ˆì„ ë¶„ì„í•´ì£¼ì„¸ìš”.")
        
        if st.button("ìš´ì „ ì ˆì°¨", key="test_operation", use_container_width=True):
            _add_test_question("ì •ìƒ ìš´ì „ ì‹œì‘ ì ˆì°¨ì™€ ì£¼ì˜ì‚¬í•­ì„ ì„¤ëª…í•´ì£¼ì„¸ìš”.")
        
        if st.button("ë„ë©´ ì‹œê°í™”", key="test_visualization", use_container_width=True):
            _add_test_question("stream_does_ai_1 ë„ë©´ì„ ì‹œê°í™”í•´ì„œ ë¶„ì„í•´ì¤˜")
        
        if st.button("ë³€ê²½ì‚¬í•­ ë¹„êµ", key="test_change_comparison", use_container_width=True):
            _add_test_question("stream_dose_ai_1ê³¼ stream_dose_ai_3ì˜ ë³€ê²½ì‚¬í•­ì„ ë¹„êµ ë¶„ì„í•´ì£¼ì„¸ìš”.")
        
        if st.button("ì¢…í•© ë¶„ì„", key="test_comprehensive", use_container_width=True):
            _add_test_question("stream_does_ai_1 ë„ë©´ì„ ì¢…í•©ì ìœ¼ë¡œ ë¶„ì„í•´ì¤˜")
    
    st.markdown("---")
    
    # ì‚¬ì´ë“œë°” ì„¤ì •
    with st.sidebar:
        st.markdown("### âš™ï¸ ì„¤ì •")
        
        # ì„ íƒëœ ë„ë©´ ì •ë³´
        if selected_drawing:
            st.success(f"ğŸ“„ ì„ íƒëœ ë„ë©´")
            st.info(selected_drawing)
        else:
            st.info("ğŸ“„ ë„ë©´ ë¯¸ì„ íƒ")
            st.caption("FILE LISTì—ì„œ ë„ë©´ì„ ì„ íƒí•˜ì„¸ìš”")
        
        # RAG ì‹œìŠ¤í…œ ìƒíƒœ í™•ì¸
        pdf_path = "data/ê³µì • Description_ê¸€.pdf"
        pdf_exists = os.path.exists(pdf_path)
        
        if pdf_exists:
            st.success("âœ… PDF ë¬¸ì„œ ë°œê²¬")
            st.info(f"ğŸ“„ {os.path.basename(pdf_path)}")
        else:
            st.error("âŒ PDF ë¬¸ì„œë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤")
            st.info(f"ğŸ“‚ ì˜ˆìƒ ê²½ë¡œ: {pdf_path}")
        
        # ê³ ê¸‰ ì„¤ì •
        st.markdown("### ğŸ›ï¸ ê³ ê¸‰ ì„¤ì •")
        use_web_search = st.checkbox("ì›¹ ê²€ìƒ‰ ë³´ì¡° í™œìš©", help="RAG ì •ë³´ê°€ ë¶€ì¡±í•  ë•Œ ì›¹ ê²€ìƒ‰ ê²°ê³¼ë¥¼ ë³´ì¡°ì ìœ¼ë¡œ í™œìš©")
        show_sources = st.checkbox("ì°¸ê³  ë¬¸ì„œ ì¶œì²˜ í‘œì‹œ", value=True)
        show_debug_info = st.checkbox("ë””ë²„ê·¸ ì •ë³´ í‘œì‹œ", help="ì¿¼ë¦¬ ìœ í˜•, ì»¨í…ìŠ¤íŠ¸ í’ˆì§ˆ ë“± ê¸°ìˆ  ì •ë³´ í‘œì‹œ")
    
    # RAG ì‹œìŠ¤í…œ ì´ˆê¸°í™”
    if pdf_exists:
        if 'rag_initialized' not in st.session_state:
            with st.spinner("ğŸ¤– RAG ì‹œìŠ¤í…œì„ ì´ˆê¸°í™”í•˜ëŠ” ì¤‘..."):
                success = st.session_state.chatbot.initialize_rag_system(pdf_path)
                if success:
                    st.session_state.rag_initialized = True
                    st.success("âœ… RAG ì‹œìŠ¤í…œì´ ì„±ê³µì ìœ¼ë¡œ ì´ˆê¸°í™”ë˜ì—ˆìŠµë‹ˆë‹¤!")
                else:
                    st.error("âŒ RAG ì‹œìŠ¤í…œ ì´ˆê¸°í™”ì— ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤.")
    else:
        st.warning("âš ï¸ PDF ë¬¸ì„œê°€ ì—†ì–´ RAG ì‹œìŠ¤í…œì„ ì´ˆê¸°í™”í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
    
    # ëŒ€í™” ê¸°ë¡ ì´ˆê¸°í™”
    if 'messages' not in st.session_state:
        st.session_state.messages = []
        # í™˜ì˜ ë©”ì‹œì§€
        welcome_message = """
ì•ˆë…•í•˜ì„¸ìš”! ì €ëŠ” P&ID ë„ë©´ ë¶„ì„ ì „ë¬¸ê°€ ì±—ë´‡ì…ë‹ˆë‹¤. ğŸ”§

**ì „ë¬¸ ë¶„ì•¼:**
- P&ID ë„ë©´ í•´ì„ ë° ë¶„ì„
- ê³„ì¸¡ê¸°ê¸° ì„¤ëª… (FT, FC, FV, PT, PC, TT, TC, LT, LC, AT, AC ë“±)
- ê³µì •ì œì–´ ì‹œìŠ¤í…œ ë¶„ì„
- ì•ˆì „ì¥ì¹˜ ë° ë¹„ìƒì •ì§€ ì‹œìŠ¤í…œ ê²€í† 
- ë„ë©´ ë³€ê²½ì‚¬í•­ ë¶„ì„

**ì§ˆë¬¸ ì˜ˆì‹œ:**
- "FT-101ì˜ ì—­í• ì€ ë¬´ì—‡ì¸ê°€ìš”?"
- "ì´ ê³µì •ì—ì„œ ì•ˆì „ì¥ì¹˜ëŠ” ì–´ë–»ê²Œ êµ¬ì„±ë˜ì–´ ìˆë‚˜ìš”?"
- "ì••ë ¥ ì¡°ì ˆ ì‹œìŠ¤í…œì— ëŒ€í•´ ì„¤ëª…í•´ì£¼ì„¸ìš”"
- "ë„ë©´ ë³€ê²½ ì‹œ ê³ ë ¤í•´ì•¼ í•  ì‚¬í•­ì€?"

ë¬´ì—‡ì´ë“  ê¶ê¸ˆí•œ ì ì„ ë¬¼ì–´ë³´ì„¸ìš”!
        """
        st.session_state.messages.append({
            "role": "assistant", 
            "content": welcome_message,
            "timestamp": datetime.now()
        })
    
    # ëŒ€í™” ì¸í„°í˜ì´ìŠ¤
    st.markdown("### ğŸ’¬ ì „ë¬¸ê°€ì™€ ëŒ€í™”í•˜ê¸°")
    
    # ëŒ€í™” ê¸°ë¡ í‘œì‹œ
    chat_container = st.container()
    with chat_container:
        for message in st.session_state.messages:
            with st.chat_message(message["role"]):
                st.write(message["content"])
                
                # íƒ€ì„ìŠ¤íƒ¬í”„ í‘œì‹œ
                if "timestamp" in message:
                    st.caption(f"â° {message['timestamp'].strftime('%Y-%m-%d %H:%M:%S')}")
                
                # ì†ŒìŠ¤ ì •ë³´ í‘œì‹œ
                if show_sources and "sources" in message and message["sources"]:
                    with st.expander("ğŸ“š ì°¸ê³  ë¬¸ì„œ ì¶œì²˜"):
                        _display_sources(message["sources"], message.get("debug_info", {}))
                
                # ì‹œê°í™” ê²°ê³¼ í‘œì‹œ (ìˆëŠ” ê²½ìš°)
                if "visualization" in message and message["visualization"]:
                    with st.expander("ğŸ–¼ï¸ ë„ë©´ ì‹œê°í™” ê²°ê³¼", expanded=True):
                        _display_visualization(message["visualization"])
                
                # ë””ë²„ê·¸ ì •ë³´ í‘œì‹œ
                if show_debug_info and "debug_info" in message:
                    debug = message["debug_info"]
                    _display_debug_info(debug)
    
    # ì‚¬ìš©ì ì…ë ¥
    if prompt := st.chat_input("P&ID ê´€ë ¨ ì§ˆë¬¸ì„ ì…ë ¥í•˜ì„¸ìš”..."):
        
        # ì‚¬ìš©ì ë©”ì‹œì§€ ì¶”ê°€
        st.session_state.messages.append({
            "role": "user", 
            "content": prompt,
            "timestamp": datetime.now()
        })
        
        # ì‚¬ìš©ì ë©”ì‹œì§€ í‘œì‹œ
        with st.chat_message("user"):
            st.write(prompt)
            st.caption(f"â° {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}")
        
        # ë´‡ ì‘ë‹µ ìƒì„±
        with st.chat_message("assistant"):
            with st.spinner("ğŸ¤” ë¶„ì„ ì¤‘..."):
                response_data = st.session_state.chatbot.generate_response(
                    prompt, 
                    use_web_search=use_web_search,
                    selected_drawing=st.session_state.get('selected_drawing_name'),
                    selected_files=st.session_state.get('selected_files_for_chat')
                )
            
            # ì‘ë‹µ í‘œì‹œ
            st.write(response_data['response'])
            st.caption(f"â° {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}")
            
            # ì†ŒìŠ¤ ì •ë³´ í‘œì‹œ
            if show_sources and response_data['sources']:
                with st.expander("ğŸ“š ì°¸ê³  ë¬¸ì„œ ì¶œì²˜"):
                    _display_sources(response_data['sources'], response_data)
            
            # ì‹œê°í™” ê²°ê³¼ í‘œì‹œ (ìˆëŠ” ê²½ìš°)
            if response_data.get('visualization'):
                with st.expander("ğŸ–¼ï¸ ë„ë©´ ì‹œê°í™” ê²°ê³¼", expanded=True):
                    _display_visualization(response_data['visualization'])
            
            # ë””ë²„ê·¸ ì •ë³´ í‘œì‹œ
            if show_debug_info:
                _display_debug_info(response_data)
        
        # ì–´ì‹œìŠ¤í„´íŠ¸ ë©”ì‹œì§€ ì €ì¥
        assistant_message = {
            "role": "assistant",
            "content": response_data['response'],
            "timestamp": datetime.now(),
            "sources": response_data.get('sources', []),
            "debug_info": {
                "query_type": response_data.get('query_type'),
                "context_quality": response_data.get('context_quality'),
                "web_search_used": response_data.get('web_search_used', False),
                "extracted_text_length": response_data.get('extracted_text_length', 0),
                "rag_chunks_count": response_data.get('rag_chunks_count', 0),
                "json_analysis": response_data.get('json_analysis'),
                "similarity_threshold": response_data.get('similarity_threshold')
            }
        }
        
        # ì‹œê°í™” ê²°ê³¼ê°€ ìˆìœ¼ë©´ ì¶”ê°€
        if response_data.get('visualization'):
            assistant_message["visualization"] = response_data['visualization']
        
        st.session_state.messages.append(assistant_message)
        
        # í˜ì´ì§€ ìƒˆë¡œê³ ì¹¨ìœ¼ë¡œ ìƒˆ ë©”ì‹œì§€ í‘œì‹œ
        st.rerun()
    
    # í•˜ë‹¨ ìœ í‹¸ë¦¬í‹°
    st.markdown("---")
    
    col1, col2, col3, col4 = st.columns(4)
    
    with col1:
        if st.button("ğŸ—‘ï¸ ëŒ€í™” ê¸°ë¡ ì‚­ì œ"):
            st.session_state.messages = []
            st.session_state.chatbot.clear_conversation_history()
            st.success("ëŒ€í™” ê¸°ë¡ì´ ì‚­ì œë˜ì—ˆìŠµë‹ˆë‹¤.")
            st.rerun()
    
    with col2:
        if st.button("ğŸ“Š ëŒ€í™” í†µê³„"):
            if hasattr(st.session_state, 'chatbot'):
                summary = st.session_state.chatbot.get_conversation_summary()
                if summary:
                    st.json(summary)
                else:
                    st.info("ëŒ€í™” ê¸°ë¡ì´ ì—†ìŠµë‹ˆë‹¤.")
    
    with col3:
        if st.button("ğŸ’¾ ëŒ€í™” ë‚´ë³´ë‚´ê¸°"):
            if hasattr(st.session_state, 'chatbot'):
                export_data = st.session_state.chatbot.export_conversation_history()
                st.download_button(
                    label="ğŸ“„ ë‹¤ìš´ë¡œë“œ",
                    data=export_data,
                    file_name=f"pid_chatbot_history_{datetime.now().strftime('%Y%m%d_%H%M%S')}.txt",
                    mime="text/plain"
                )
    
    with col4:
        if st.button("ğŸ”„ RAG ì‹œìŠ¤í…œ ì¬êµ¬ì¶•"):
            if pdf_exists:
                with st.spinner("RAG ì‹œìŠ¤í…œì„ ì¬êµ¬ì¶•í•˜ëŠ” ì¤‘..."):
                    success = st.session_state.chatbot.rag_system.build_vector_database(pdf_path)
                    if success:
                        st.success("âœ… RAG ì‹œìŠ¤í…œì´ ì¬êµ¬ì¶•ë˜ì—ˆìŠµë‹ˆë‹¤!")
                    else:
                        st.error("âŒ RAG ì‹œìŠ¤í…œ ì¬êµ¬ì¶•ì— ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤.")
            else:
                st.error("PDF íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
    
    # ë„ì›€ë§
    with st.expander("ğŸ“– ì‚¬ìš©ë²• ë° íŒ"):
        st.markdown("""
        ### ğŸ¯ íš¨ê³¼ì ì¸ ì§ˆë¬¸ ë°©ë²•
        
        **1. êµ¬ì²´ì ì¸ ì§ˆë¬¸í•˜ê¸°**
        - âŒ "ì´ê²Œ ë­ì•¼?"
        - âœ… "FT-101 ê³„ì¸¡ê¸°ì˜ ì—­í• ê³¼ ìœ„ì¹˜ë¥¼ ì„¤ëª…í•´ì£¼ì„¸ìš”"
        
        **2. ì»¨í…ìŠ¤íŠ¸ ì œê³µ**
        - âŒ "ë¬¸ì œê°€ ìˆì–´"
        - âœ… "ì••ë ¥ ì¡°ì ˆ ì‹œìŠ¤í…œì—ì„œ PC-201ì´ ì œëŒ€ë¡œ ì‘ë™í•˜ì§€ ì•ŠëŠ” ê²½ìš° í™•ì¸í•´ì•¼ í•  ì‚¬í•­"
        
        **3. ë¶„ì„ ìš”ì²­**
        - "ë„ë©´ì˜ ì•ˆì „ì¥ì¹˜ ì‹œìŠ¤í…œì„ ë¶„ì„í•´ì£¼ì„¸ìš”"
        - "ì´ ê³µì •ì˜ ì œì–´ ë¡œì§ì„ ì„¤ëª…í•´ì£¼ì„¸ìš”"
        - "ë¹„ìƒì •ì§€ ì‹œí€€ìŠ¤ë¥¼ ê²€í† í•´ì£¼ì„¸ìš”"
        
        ### ğŸ”§ ì§€ì›í•˜ëŠ” ê¸°ëŠ¥
        - P&ID ë„ë©´ í•´ì„
        - ê³„ì¸¡ê¸°ê¸° ì„¤ëª… (FT, FC, FV, PT, PC, TT, TC, LT, LC, AT, AC ë“±)
        - ê³µì • ì•ˆì „ì„± ë¶„ì„
        - ì œì–´ ì‹œìŠ¤í…œ ê²€í† 
        - ë„ë©´ ë³€ê²½ì‚¬í•­ ë¶„ì„
        """)
    
    # ë©´ì±…ì‚¬í•­
    st.markdown("---")
    st.caption("âš ï¸ ì´ ì±—ë´‡ì€ ë³´ì¡° ë„êµ¬ì´ë©°, ì¤‘ìš”í•œ ì•ˆì „ ê²°ì •ì€ ë°˜ë“œì‹œ ì „ë¬¸ê°€ì™€ ìƒì˜í•˜ì‹œê¸° ë°”ëë‹ˆë‹¤.")

def _add_test_question(question_text):
    """í…ŒìŠ¤íŠ¸ ì§ˆë¬¸ì„ ëŒ€í™”ì— ì¶”ê°€í•˜ê³  ìë™ ì‘ë‹µ ìƒì„±"""
    
    if 'messages' not in st.session_state:
        st.session_state.messages = []
    
    # ì‚¬ìš©ì ì§ˆë¬¸ ì¶”ê°€
    st.session_state.messages.append({
        "role": "user",
        "content": question_text,
        "timestamp": datetime.now()
    })
    
    # ìë™ ì‘ë‹µ ìƒì„±
    with st.spinner("ğŸ¤” ë¶„ì„ ì¤‘..."):
        response_data = st.session_state.chatbot.generate_response(
            question_text,
            use_web_search=False,
            selected_drawing=st.session_state.get('selected_drawing_name'),
            selected_files=st.session_state.get('selected_files_for_chat')
        )
    
    # ì–´ì‹œìŠ¤í„´íŠ¸ ë©”ì‹œì§€ ì €ì¥
    assistant_message = {
        "role": "assistant",
        "content": response_data['response'],
        "timestamp": datetime.now(),
        "sources": response_data.get('sources', []),
        "debug_info": {
            "query_type": response_data.get('query_type'),
            "context_quality": response_data.get('context_quality'),
            "web_search_used": response_data.get('web_search_used', False),
            "selected_files_count": response_data.get('selected_files_count', 0),
            "files_processed": response_data.get('selected_files_count', 0)  # ì´ë¯¸ì§€ ì²˜ë¦¬ ëŒ€ì‹  íŒŒì¼ ì²˜ë¦¬ ìˆ˜ë¡œ ë³€ê²½
        }
    }
    
    # ì‹œê°í™” ê²°ê³¼ê°€ ìˆìœ¼ë©´ ì¶”ê°€
    if response_data.get('visualization'):
        assistant_message["visualization"] = response_data['visualization']
    
    st.session_state.messages.append(assistant_message)
    
    # í˜ì´ì§€ ìƒˆë¡œê³ ì¹¨
    st.rerun()

def get_file_details(conn, file_id):
    """ë°ì´í„°ë² ì´ìŠ¤ì—ì„œ íŒŒì¼ ìƒì„¸ ì •ë³´ ì¡°íšŒ"""
    try:
        cursor = conn.cursor()
        cursor.execute("""
            SELECT d_id, d_name, "user", create_date, image_path, json_data
            FROM domyun WHERE d_id = %s
        """, (file_id,))
        row = cursor.fetchone()
        
        if row:
            return {
                'id': row[0],
                'name': row[1],
                'user': row[2],
                'create_date': row[3],
                'image_path': row[4],
                'json_data': row[5]
            }
        return None
    except Exception:
        return None

def count_ocr_fields(json_data):
    """JSON ë°ì´í„°ì—ì„œ OCR í•„ë“œ ê°œìˆ˜ ê³„ì‚°"""
    try:
        # ìƒˆë¡œìš´ êµ¬ì¡° ('ocr')
        if 'ocr' in json_data and json_data['ocr']:
            ocr_data = json_data['ocr']
            if isinstance(ocr_data, dict) and 'images' in ocr_data:
                total_fields = 0
                for img in ocr_data['images']:
                    if 'fields' in img:
                        total_fields += len(img['fields'])
                return total_fields
        # ì´ì „ êµ¬ì¡° ('ocr_data')
        elif 'ocr_data' in json_data and json_data['ocr_data']:
            ocr_data = json_data['ocr_data']
            if isinstance(ocr_data, dict) and 'images' in ocr_data:
                total_fields = 0
                for img in ocr_data['images']:
                    if 'fields' in img:
                        total_fields += len(img['fields'])
                return total_fields
        return 0
    except:
        return 0

def count_detection_objects(json_data):
    """JSON ë°ì´í„°ì—ì„œ Detection ê°ì²´ ê°œìˆ˜ ê³„ì‚°"""
    try:
        # ìƒˆë¡œìš´ êµ¬ì¡° ('detecting')
        if 'detecting' in json_data and json_data['detecting']:
            detection_data = json_data['detecting']
            if isinstance(detection_data, dict) and 'data' in detection_data and 'boxes' in detection_data['data']:
                boxes = detection_data['data']['boxes']
                return len([box for box in boxes if isinstance(box, dict) and 'label' in box])
        # ì´ì „ êµ¬ì¡° ('detection_data')
        elif 'detection_data' in json_data and json_data['detection_data']:
            detection_data = json_data['detection_data']
            if isinstance(detection_data, dict) and 'detections' in detection_data:
                detections = detection_data['detections']
                return len([det for det in detections if isinstance(det, dict) and 'label' in det])
        return 0
    except:
        return 0

def extract_ocr_text_preview(json_data):
    """JSON ë°ì´í„°ì—ì„œ OCR í…ìŠ¤íŠ¸ ë¯¸ë¦¬ë³´ê¸° ì¶”ì¶œ"""
    try:
        if not json_data:
            return ""
        
        data = json_data if isinstance(json_data, dict) else json.loads(json_data)
        texts = []
        
        # ìƒˆë¡œìš´ êµ¬ì¡° ('ocr')
        if 'ocr' in data and data['ocr']:
            ocr_data = data['ocr']
            if isinstance(ocr_data, dict) and 'images' in ocr_data:
                for img in ocr_data['images']:
                    if 'fields' in img:
                        for field in img['fields']:
                            if 'inferText' in field and field['inferText']:
                                texts.append(field['inferText'])
        
        # ì´ì „ êµ¬ì¡° ('ocr_data')
        elif 'ocr_data' in data and data['ocr_data']:
            ocr_data = data['ocr_data']
            if isinstance(ocr_data, dict) and 'images' in ocr_data:
                for img in ocr_data['images']:
                    if 'fields' in img:
                        for field in img['fields']:
                            if 'inferText' in field and field['inferText']:
                                texts.append(field['inferText'])
        
        return " | ".join(texts)
    except:
        return ""

def _display_sources(sources, debug_info):
    """ì†ŒìŠ¤ ì •ë³´ í‘œì‹œ í•¨ìˆ˜ - ëª¨ë“  ì†ŒìŠ¤ íƒ€ì… ì§€ì›"""
    if not sources:
        return
    
    # ê³ ìœ  í‚¤ ìƒì„±ì„ ìœ„í•œ íƒ€ì„ìŠ¤íƒ¬í”„
    timestamp = str(int(time.time() * 1000))
    
    # ì†ŒìŠ¤ íƒ€ì…ë³„ ë¶„ë¥˜
    database_sources = [s for s in sources if s.get('type') == 'database']
    drawing_search_sources = [s for s in sources if s.get('type') == 'drawing_search']
    rag_sources = [s for s in sources if s.get('type') == 'rag']
    web_sources = [s for s in sources if s.get('type') == 'web']
    
    # ìœ ì‚¬ë„ ì„ê³„ê°’ ì •ë³´
    threshold = debug_info.get('similarity_threshold', 0.4)
    
    # í†µê³„ ì •ë³´ í‘œì‹œ
    col1, col2, col3, col4 = st.columns(4)
    with col1:
        st.metric("ğŸ—„ï¸ ë°ì´í„°ë² ì´ìŠ¤", len(database_sources))
    with col2:
        st.metric("ğŸ” ë„ë©´ ê²€ìƒ‰", len(drawing_search_sources))
    with col3:
        st.metric("ğŸ“– RAG ì†ŒìŠ¤", len(rag_sources))
    with col4:
        st.metric("ğŸŒ ì›¹ ì†ŒìŠ¤", len(web_sources))
    
    # ì¶”ê°€ í†µê³„ í–‰
    if threshold:
        col1, col2 = st.columns(2)
        with col1:
            st.metric("ğŸ¯ ìœ ì‚¬ë„ ì„ê³„ê°’", f"{threshold}")
        with col2:
            total_sources = len(database_sources) + len(drawing_search_sources) + len(rag_sources) + len(web_sources)
            st.metric("ğŸ“Š ì´ ì†ŒìŠ¤ ìˆ˜", total_sources)
    
    st.markdown("---")
    
    # ë„ë©´ ê²€ìƒ‰ ê²°ê³¼ í‘œì‹œ (ìµœìš°ì„ )
    if drawing_search_sources:
        st.markdown("### ğŸ” ë„ë©´ ê²€ìƒ‰ ê²°ê³¼")
        for i, source in enumerate(drawing_search_sources, 1):
            st.write(f"{source.get('icon', 'ğŸ”')} **{source.get('source', 'N/A')}**")
            
            st.markdown(f"**ğŸ”¸ ê²€ìƒ‰ ê²°ê³¼ {i}:**")
            st.write(f"- **ì •ë³´:** {source.get('content_preview', 'N/A')}")
            st.write(f"- **í’ˆì§ˆ:** {source.get('quality', 'N/A').upper()}")
            st.markdown("")  # ë¹ˆ ì¤„ ì¶”ê°€
    
    # ë°ì´í„°ë² ì´ìŠ¤ ì†ŒìŠ¤ í‘œì‹œ
    if database_sources:
        st.markdown("### ğŸ—„ï¸ ë°ì´í„°ë² ì´ìŠ¤ ì†ŒìŠ¤ (ì„ íƒëœ ë„ë©´)")
        for i, source in enumerate(database_sources, 1):
            st.write(f"{source.get('icon', 'ğŸ—„ï¸')} **{source.get('source', 'N/A')}**")
            
            # expander ëŒ€ì‹  indented content ì‚¬ìš©
            st.markdown(f"**ğŸ”¸ ë„ë©´ ì •ë³´ {i}:**")
            st.write(f"- **ì„¤ëª…:** {source.get('content_preview', 'N/A')}")
            st.write(f"- **í’ˆì§ˆ:** {source.get('quality', 'N/A').upper()}")
            st.markdown("")  # ë¹ˆ ì¤„ ì¶”ê°€
    
    # RAG ì†ŒìŠ¤ í‘œì‹œ
    if rag_sources:
        st.markdown("### ğŸ“– RAG ë°ì´í„°ë² ì´ìŠ¤ ì†ŒìŠ¤")
        
        # ê³ í’ˆì§ˆê³¼ ì €í’ˆì§ˆ ë¶„ë¦¬
        high_quality = [s for s in rag_sources if s.get('quality') == 'high']
        low_quality = [s for s in rag_sources if s.get('quality') == 'low']
        
        if high_quality:
            st.markdown(f"**ğŸŸ¢ ê³ í’ˆì§ˆ ì†ŒìŠ¤ (ìœ ì‚¬ë„ â‰¥ {threshold})**")
            for i, source in enumerate(high_quality, 1):
                score = source.get('score', 0)
                page = source.get('page', 'N/A')
                
                # ìœ ì‚¬ë„ì— ë”°ë¥¸ ìƒ‰ìƒ ê²°ì •
                if score >= 0.7:
                    score_color = "ğŸŸ¢"
                elif score >= 0.5:
                    score_color = "ğŸŸ¡"
                else:
                    score_color = "ğŸŸ "
                
                st.write(f"{source.get('icon', 'ğŸ“–')} **ì†ŒìŠ¤ {i}** - í˜ì´ì§€ {page} {score_color} (ìœ ì‚¬ë„: {score:.3f})")
                
                # expander ëŒ€ì‹  toggle í˜•íƒœë¡œ í‘œì‹œ
                show_content = st.checkbox(f"ë‚´ìš© ë¯¸ë¦¬ë³´ê¸° ë³´ê¸° - ì†ŒìŠ¤ {i}", key=f"show_source_{i}_{timestamp}")
                if show_content:
                    st.code(source.get('content_preview', 'N/A'), language='text')
                st.markdown("")  # ë¹ˆ ì¤„ ì¶”ê°€
        
        if low_quality:
            st.markdown(f"**ğŸŸ¡ ì°¸ê³ ìš© ì†ŒìŠ¤ (ìœ ì‚¬ë„ < {threshold})**")
            for i, source in enumerate(low_quality, len(high_quality) + 1):
                score = source.get('score', 0)
                page = source.get('page', 'N/A')
                
                st.write(f"{source.get('icon', 'ğŸ“–')} **ì°¸ê³  {i}** - í˜ì´ì§€ {page} ğŸŸ¡ (ìœ ì‚¬ë„: {score:.3f})")
                
                # expander ëŒ€ì‹  toggle í˜•íƒœë¡œ í‘œì‹œ
                show_content = st.checkbox(f"ë‚´ìš© ë¯¸ë¦¬ë³´ê¸° ë³´ê¸° - ì°¸ê³  {i}", key=f"show_ref_{i}_{timestamp}")
                if show_content:
                    st.code(source.get('content_preview', 'N/A'), language='text')
                st.markdown("")  # ë¹ˆ ì¤„ ì¶”ê°€
    
    # ì›¹ ì†ŒìŠ¤ í‘œì‹œ
    if web_sources:
        st.markdown("### ğŸŒ ì›¹ ê²€ìƒ‰ ì†ŒìŠ¤")
        for i, source in enumerate(web_sources, 1):
            st.write(f"{source.get('icon', 'ğŸŒ')} **{source.get('source', 'N/A')}**")
            
            # expander ëŒ€ì‹  toggle í˜•íƒœë¡œ í‘œì‹œ
            show_content = st.checkbox(f"ì›¹ ê²€ìƒ‰ ê²°ê³¼ ë³´ê¸° - {i}", key=f"show_web_{i}_{timestamp}")
            if show_content:
                st.code(source.get('content_preview', 'N/A'), language='text')
            st.markdown("")  # ë¹ˆ ì¤„ ì¶”ê°€
    
    # ì‹œê°í™” ì†ŒìŠ¤ í‘œì‹œ
    visualization_sources = [s for s in sources if s.get('type') == 'visualization']
    if visualization_sources:
        st.markdown("### ğŸ¨ ì‹œê°í™” ì†ŒìŠ¤")
        for i, source in enumerate(visualization_sources, 1):
            st.write(f"{source.get('icon', 'ğŸ¨')} **{source.get('source', 'N/A')}**")
            st.write(f"- **ë‚´ìš©:** {source.get('content_preview', 'N/A')}")
            st.write(f"- **í’ˆì§ˆ:** {source.get('quality', 'N/A').upper()}")
            st.markdown("")  # ë¹ˆ ì¤„ ì¶”ê°€
    
    # ì†ŒìŠ¤ê°€ ì—†ëŠ” ê²½ìš°
    if not database_sources and not drawing_search_sources and not rag_sources and not web_sources and not visualization_sources:
        st.info("ğŸ“ ì´ ë‹µë³€ì€ ì¼ë°˜ì ì¸ P&ID ì§€ì‹ì„ ë°”íƒ•ìœ¼ë¡œ ìƒì„±ë˜ì—ˆìŠµë‹ˆë‹¤.")

def _display_debug_info(debug_info):
    """ë””ë²„ê·¸ ì •ë³´ í‘œì‹œ í•¨ìˆ˜"""
    query_type = debug_info.get('query_type', 'N/A')
    
    # ì¿¼ë¦¬ íƒ€ì…ë³„ ìƒ‰ìƒ ë° ì•„ì´ì½˜
    if query_type == "comprehensive_analysis":
        type_display = "ğŸ”¬ ë¶„ì„"
        color = "purple"
    elif query_type == "drawing_visualization":
        type_display = "ğŸ¨ ë„ë©´ì‹œê°í™”"
        color = "teal"
    
    # ë©”íŠ¸ë¦­ í‘œì‹œ
    col1, col2, col3, col4 = st.columns(4)
    
    with col1:
        st.metric("ğŸ” ì¿¼ë¦¬ ìœ í˜•", type_display)
    
    with col2:
        context_quality = debug_info.get('context_quality', 'N/A')
        quality_icon = {"high": "ğŸŸ¢", "medium": "ğŸŸ¡", "low": "ğŸ”´"}.get(context_quality, "âšª")
        st.metric("ğŸ“Š ì»¨í…ìŠ¤íŠ¸ í’ˆì§ˆ", f"{quality_icon} {context_quality}")
    
    with col3:
        web_used = debug_info.get('web_search_used', False)
        # ë‚´ë¶€ ë°ì´í„°ì¸ ê²½ìš° ì›¹ ê²€ìƒ‰ ê¸ˆì§€ í‘œì‹œ
        if query_type == "internal_data":
            st.metric("ğŸŒ ì›¹ ê²€ìƒ‰", "ğŸ”’ ê¸ˆì§€ë¨")
        else:
            st.metric("ğŸŒ ì›¹ ê²€ìƒ‰", "âœ… ì‚¬ìš©ë¨" if web_used else "âŒ ì‚¬ìš©ì•ˆë¨")
    
    with col4:
        if 'high_quality_sources' in debug_info and 'low_quality_sources' in debug_info:
            high_count = debug_info.get('high_quality_sources', 0)
            low_count = debug_info.get('low_quality_sources', 0)
            st.metric("ğŸ“ˆ ì†ŒìŠ¤ í’ˆì§ˆ", f"ê³ í’ˆì§ˆ: {high_count}, ì°¸ê³ : {low_count}")
    
    # ì„ íƒëœ íŒŒì¼ ì •ë³´ í‘œì‹œ
    selected_files_count = debug_info.get('selected_files_count', 0)
    if selected_files_count > 0:
        st.markdown("---")
        st.markdown("### ğŸ“ ì„ íƒëœ íŒŒì¼ ë°ì´í„°")
        
        col1, col2, col3, col4 = st.columns(4)
        with col1:
            st.metric("ğŸ“„ ì„ íƒëœ íŒŒì¼", f"{selected_files_count}ê°œ")
        
        with col2:
            ocr_data_included = debug_info.get('ocr_data_included', False)
            st.metric("ğŸ“ OCR ë°ì´í„°", "âœ… í¬í•¨ë¨" if ocr_data_included else "âŒ ì—†ìŒ")
        
        with col3:
            detection_data_included = debug_info.get('detection_data_included', False)
            st.metric("ğŸ¯ Detection ë°ì´í„°", "âœ… í¬í•¨ë¨" if detection_data_included else "âŒ ì—†ìŒ")
        
        with col4:
            total_context_length = debug_info.get('total_context_length', 0)
            st.metric("ğŸ“Š ì´ ì»¨í…ìŠ¤íŠ¸", f"{total_context_length}ì")
        
        # íŒŒì¼ë³„ ìƒì„¸ ì •ë³´ í‘œì‹œ
        if debug_info.get('file_details'):
            with st.expander("ğŸ” íŒŒì¼ë³„ ìƒì„¸ ì •ë³´", expanded=False):
                for i, file_detail in enumerate(debug_info['file_details'], 1):
                    st.markdown(f"**íŒŒì¼ {i}: {file_detail.get('name', 'Unknown')}**")
                    st.write(f"- OCR í…ìŠ¤íŠ¸: {file_detail.get('ocr_count', 0)}ê°œ")
                    st.write(f"- Detection ê°ì²´: {file_detail.get('detection_count', 0)}ê°œ")
                    st.write(f"- JSON ë°ì´í„° í¬ê¸°: {file_detail.get('json_size', 0)}ì")
                    
                    # OCR í…ìŠ¤íŠ¸ ë¯¸ë¦¬ë³´ê¸°
                    if file_detail.get('ocr_preview'):
                        st.text_area(f"OCR í…ìŠ¤íŠ¸ ë¯¸ë¦¬ë³´ê¸° (íŒŒì¼ {i})", 
                                   value=file_detail['ocr_preview'][:200] + "..." if len(file_detail['ocr_preview']) > 200 else file_detail['ocr_preview'], 
                                   height=80, disabled=True, key=f"debug_ocr_{i}", label_visibility="collapsed")
                    
                    # Detection ê°ì²´ ë¯¸ë¦¬ë³´ê¸°
                    if file_detail.get('detection_preview'):
                        st.text_area(f"Detection ê°ì²´ ë¯¸ë¦¬ë³´ê¸° (íŒŒì¼ {i})", 
                                   value=file_detail['detection_preview'][:200] + "..." if len(file_detail['detection_preview']) > 200 else file_detail['detection_preview'], 
                                   height=80, disabled=True, key=f"debug_detection_{i}", label_visibility="collapsed")
                    
                    if i < len(debug_info['file_details']):
                        st.divider()
    
    # ì¢…í•© ë¶„ì„ ì „ìš© ì •ë³´ í‘œì‹œ
    if query_type == "comprehensive_analysis":
        st.markdown("---")
        st.markdown("### ğŸ”¬ ì¢…í•© ë¶„ì„ ìƒì„¸ ì •ë³´")
        
        col1, col2, col3, col4 = st.columns(4)
        with col1:
            extracted_length = debug_info.get('extracted_text_length', 0)
            st.metric("ğŸ“ ì¶”ì¶œ í…ìŠ¤íŠ¸", f"{extracted_length}ì")
        
        with col2:
            rag_chunks = debug_info.get('rag_chunks_count', 0)
            st.metric("ğŸ“– RAG ì²­í¬", f"{rag_chunks}ê°œ")
        
        with col3:
            has_visualization = "âœ… í¬í•¨" if debug_info.get('visualization') else "âŒ ì—†ìŒ"
            st.metric("ğŸ¨ ì‹œê°í™”", has_visualization)
        
        with col4:
            has_json = "âœ… í¬í•¨" if debug_info.get('json_analysis') else "âŒ ì—†ìŒ"
            st.metric("ğŸ“Š JSON ë¶„ì„", has_json)
    
    # ì¶”ê°€ ì„¸ë¶€ ì •ë³´
    if debug_info.get('similarity_threshold'):
        extra_info = f"ğŸ¯ ìœ ì‚¬ë„ ì„ê³„ê°’: {debug_info['similarity_threshold']} | â±ï¸ ìƒì„± ì‹œê°„: {datetime.now().strftime('%H:%M:%S')}"
        
        # ë‚´ë¶€ ë°ì´í„° íƒ€ì…ì¸ ê²½ìš° ë³´ì•ˆ ì•Œë¦¼ ì¶”ê°€
        if query_type == "internal_data":
            extra_info += " | ğŸ”’ ë³´ì•ˆ: RAG ì „ìš©"
        elif query_type == "comprehensive_analysis":
            extra_info += " | ğŸ”¬ í†µí•©: RAG+JSON+ì‹œê°í™”"
        
        # ì„ íƒëœ íŒŒì¼ì´ ìˆëŠ” ê²½ìš° íŒŒì¼ ì •ë³´ ì¶”ê°€
        if selected_files_count > 0:
            extra_info += f" | ğŸ“ íŒŒì¼: {selected_files_count}ê°œ"
        
        st.caption(extra_info)

def _display_visualization(visualization_data):
    """ì‹œê°í™” ê²°ê³¼ í‘œì‹œ í•¨ìˆ˜"""
    if not visualization_data:
        st.error("ì‹œê°í™” ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.")
        return
    
    # ë³€ê²½ ë¹„êµ ì‹œê°í™”ì¸ì§€ í™•ì¸
    if 'as_is_image' in visualization_data and 'to_be_image' in visualization_data:
        # ë³€ê²½ ë¹„êµ ì‹œê°í™” ì²˜ë¦¬
        st.markdown("### ğŸ”„ ë³€ê²½ ë¹„êµ ì‹œê°í™”")
        
        # í†µê³„ ì •ë³´ í‘œì‹œ
        stats = visualization_data.get('statistics', {})
        col1, col2, col3, col4 = st.columns(4)
        
        with col1:
            st.metric("ğŸ“‹ AS-IS ê°ì²´", f"{stats.get('total_as_is', 0)}ê°œ")
        with col2:
            st.metric("ğŸ“‹ TO-BE ê°ì²´", f"{stats.get('total_to_be', 0)}ê°œ")
        with col3:
            st.metric("ğŸ”´ ì œê±°ëœ ê°ì²´", f"{stats.get('removed_count', 0)}ê°œ")
        with col4:
            st.metric("ğŸŸ¢ ì¶”ê°€ëœ ê°ì²´", f"{stats.get('added_count', 0)}ê°œ")
        
        # AS-ISì™€ TO-BE ì´ë¯¸ì§€ë¥¼ ë‚˜ë€íˆ í‘œì‹œ
        st.markdown("### ğŸ–¼ï¸ ë¹„êµ ì´ë¯¸ì§€")
        
        col1, col2 = st.columns(2)
        
        with col1:
            as_is_data = visualization_data.get('as_is_image', {})
            if as_is_data and 'image_base64' in as_is_data:
                st.markdown(f"#### {as_is_data.get('title', 'AS-IS')}")
                image_html = f'<img src="data:image/png;base64,{as_is_data["image_base64"]}" style="max-width: 100%; height: auto;" />'
                st.markdown(image_html, unsafe_allow_html=True)
                st.caption(f"ê°•ì¡°ëœ ê°ì²´: {as_is_data.get('highlight_count', 0)}ê°œ / ì „ì²´: {as_is_data.get('total_objects', 0)}ê°œ")
        
        with col2:
            to_be_data = visualization_data.get('to_be_image', {})
            if to_be_data and 'image_base64' in to_be_data:
                st.markdown(f"#### {to_be_data.get('title', 'TO-BE')}")
                image_html = f'<img src="data:image/png;base64,{to_be_data["image_base64"]}" style="max-width: 100%; height: auto;" />'
                st.markdown(image_html, unsafe_allow_html=True)
                st.caption(f"ê°•ì¡°ëœ ê°ì²´: {to_be_data.get('highlight_count', 0)}ê°œ / ì „ì²´: {to_be_data.get('total_objects', 0)}ê°œ")
        
        # ë²”ë¡€ í‘œì‹œ
        st.markdown("### ğŸ“Œ ë³€ê²½ ë¹„êµ ë²”ë¡€")
        col1, col2 = st.columns(2)
        with col1:
            st.markdown("ğŸ”´ **ë¹¨ê°„ìƒ‰ ë°•ìŠ¤**: ë³€ê²½ëœ ê°ì²´ (ì œê±°/ì¶”ê°€)")
        with col2:
            st.markdown("âšª **íšŒìƒ‰ ë°•ìŠ¤**: ë³€ê²½ë˜ì§€ ì•Šì€ ê°ì²´")
        
        # ìƒì„¸ ë³€ê²½ ë‚´ì—­ í‘œì‹œ
        if visualization_data.get('analysis_summary'):
            st.markdown("### ğŸ“‹ ìƒì„¸ ë³€ê²½ ë‚´ì—­")
            st.text_area("ìƒì„¸ ë³€ê²½ ë‚´ì—­", value=visualization_data['analysis_summary'], height=300, disabled=True, label_visibility="collapsed")
        
    else:
        # ê¸°ì¡´ ë‹¨ì¼ ë„ë©´ ì‹œê°í™” ì²˜ë¦¬
        st.markdown("### ğŸ“Š ì‹œê°í™” ì •ë³´")
        
        col1, col2, col3, col4 = st.columns(4)
        with col1:
            st.metric("ğŸ“„ ë„ë©´ëª…", visualization_data.get('drawing_name', 'N/A'))
        with col2:
            st.metric("ğŸ”¢ OCR í…ìŠ¤íŠ¸", f"{visualization_data.get('ocr_count', 0)}ê°œ")
        with col3:
            st.metric("ğŸ¯ Detection", f"{visualization_data.get('detection_count', 0)}ê°œ")
        with col4:
            original_size = visualization_data.get('original_size', (0, 0))
            st.metric("ğŸ“ ì´ë¯¸ì§€ í¬ê¸°", f"{original_size[0]}Ã—{original_size[1]}")
        
        # ì´ë¯¸ì§€ í‘œì‹œ
        if 'image_base64' in visualization_data:
            st.markdown("### ğŸ–¼ï¸ ë¶„ì„ëœ ë„ë©´")
            
            # Base64 ì´ë¯¸ì§€ í‘œì‹œ
            import base64
            image_html = f'<img src="data:image/png;base64,{visualization_data["image_base64"]}" style="max-width: 100%; height: auto;" />'
            st.markdown(image_html, unsafe_allow_html=True)
            
            # ë²”ë¡€ í‘œì‹œ
            st.markdown("### ğŸ“Œ ë²”ë¡€")
            col1, col2 = st.columns(2)
            with col1:
                st.markdown("ğŸ”µ **íŒŒë€ìƒ‰ ë°•ìŠ¤**: OCR í…ìŠ¤íŠ¸ ì˜ì—­")
            with col2:
                st.markdown("ğŸ”´ **ë¹¨ê°„ìƒ‰ ë°•ìŠ¤**: AI ê°ì§€ ê°ì²´")
            
            # ìƒì„¸ ì •ë³´ - expander ëŒ€ì‹  ì¼ë°˜ ì»¨í…Œì´ë„ˆ ì‚¬ìš©
            st.markdown("### ğŸ“‹ ìƒì„¸ ë¶„ì„ ì •ë³´")
            
            # JSON ë°ì´í„°ì—ì„œ ì´ë¯¸ì§€ í¬ê¸° ì •ë³´ ê°€ì ¸ì˜¤ê¸°
            json_data = visualization_data.get('json_data', {})
            image_size = json_data.get('image_size', {})
            width = image_size.get('width', 0)
            height = image_size.get('height', 0)
            
            st.write(f"**ì›ë³¸ í¬ê¸°:** {width} Ã— {height}")
            st.write(f"**ë¶„ì„ í¬ê¸°:** {resized_size[0]} Ã— {resized_size[1]}")
            
            # OCRê³¼ Detection ë¯¸ë¦¬ë³´ê¸° í‘œì‹œ
            st.markdown("### ğŸ“ ë°ì´í„° ë¯¸ë¦¬ë³´ê¸°")
            
            # OCR ë¯¸ë¦¬ë³´ê¸°
            ocr_preview = visualization_data.get('ocr_preview', '')
            if ocr_preview:
                st.markdown("#### ğŸ”µ OCR í…ìŠ¤íŠ¸")
                st.text_area("OCR í…ìŠ¤íŠ¸ ë¯¸ë¦¬ë³´ê¸°", 
                           value=ocr_preview[:200] + "..." if len(ocr_preview) > 200 else ocr_preview,
                           height=100, disabled=True, key="ocr_preview", label_visibility="collapsed")
            
            # Detection ë¯¸ë¦¬ë³´ê¸°
            detection_preview = visualization_data.get('detection_preview', '')
            if detection_preview:
                st.markdown("#### ğŸ”´ Detection ê°ì²´")
                st.text_area("Detection ê°ì²´ ë¯¸ë¦¬ë³´ê¸°",
                           value=detection_preview[:200] + "..." if len(detection_preview) > 200 else detection_preview,
                           height=100, disabled=True, key="detection_preview", label_visibility="collapsed")
            
            # ë¶„ì„ ìš”ì•½ ì •ë³´ë¥¼ ë³´ê¸° ì¢‹ê²Œ í‘œì‹œ
            analysis_summary = visualization_data.get('analysis_summary', {})
            if isinstance(analysis_summary, dict):
                st.markdown("#### ğŸ“Š ë¶„ì„ í†µê³„")
                col1, col2 = st.columns(2)
                with col1:
                    st.metric("ì´ ê°ì²´ ìˆ˜", analysis_summary.get('total_objects', 0))
                    if 'image_size' in analysis_summary:
                        st.write(f"**ì´ë¯¸ì§€ í¬ê¸°:** {analysis_summary['image_size'].get('width', 0)} Ã— {analysis_summary['image_size'].get('height', 0)}")
                with col2:
                    st.metric("OCR í…ìŠ¤íŠ¸ ìˆ˜", analysis_summary.get('ocr_text_count', 0))
                    if 'detected_objects' in analysis_summary:
                        st.write(f"**ê°ì§€ëœ ê°ì²´:** {len(analysis_summary['detected_objects'])}ê°œ")
            else:
                st.write(f"**ë¶„ì„ ìš”ì•½:** {analysis_summary}")
            
            # ë„ë©´ ë°ì´í„° ì •ë³´
            drawing_data = visualization_data.get('drawing_data', {})
            if drawing_data:
                st.write(f"**ë“±ë¡ì¼:** {drawing_data.get('create_date', 'N/A')}")
                st.write(f"**ë“±ë¡ì:** {drawing_data.get('user', 'N/A')}")
        else:
            st.error("ì‹œê°í™”ëœ ì´ë¯¸ì§€ê°€ ì—†ìŠµë‹ˆë‹¤.")

if __name__ == "__main__":
    show() 