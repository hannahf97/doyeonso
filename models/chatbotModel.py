#!/usr/bin/env python3
"""
P&ID ì „ë¬¸ê°€ ì±—ë´‡ ëª¨ë¸ - Streamlit ì—°ë™ìš©
"""

import os
import pickle
import torch
import json
from sentence_transformers import SentenceTransformer
from utils.rag_system_kiwi import RAGSystemWithKiwi
from openai import OpenAI
from loguru import logger
from typing import List, Dict, Optional, Tuple
from datetime import datetime
from dotenv import load_dotenv
from config.database_config import get_db_connection
# ì´ë¯¸ì§€ ì²˜ë¦¬ë¥¼ ìœ„í•œ import ì¶”ê°€
from PIL import Image, ImageDraw, ImageFont
import io
import base64

# .env íŒŒì¼ ë¡œë“œ
load_dotenv()

class PIDExpertChatbot:
    """P&ID ë„ë©´ ë¶„ì„ ì „ë¬¸ê°€ ì±—ë´‡"""
    
    def __init__(self):
        """ì±—ë´‡ ì´ˆê¸°í™”"""
        
        # OpenAI í´ë¼ì´ì–¸íŠ¸ ì´ˆê¸°í™”
        self.openai_api_key = os.getenv('OPENAI_API_KEY')
        if self.openai_api_key:
            self.client = OpenAI(api_key=self.openai_api_key)
        else:
            self.client = None
            logger.warning("OpenAI API í‚¤ê°€ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")
        
        # ì„ë² ë”© ëª¨ë¸ ì´ˆê¸°í™”
        self.embedder = SentenceTransformer('sentence-transformers/all-MiniLM-L6-v2')
        
        # RAG ì‹œìŠ¤í…œ ì´ˆê¸°í™”
        self.kiwi_rag = RAGSystemWithKiwi()
        
        # ë²¡í„° ë°ì´í„°ë² ì´ìŠ¤ ìƒíƒœ
        self.chunks = None
        self.embeddings = None
        
        # ëŒ€í™” ê¸°ë¡
        self.conversation_history = []
        
        # ìƒíƒœ ì €ì¥ ê²½ë¡œ
        self.STATE_PATH = "./state/"
        
        # ì „ë¬¸ê°€ í˜ë¥´ì†Œë‚˜ ì •ì˜
        self.expert_persona = """ë‹¹ì‹ ì€ 20ë…„ ê²½ë ¥ì˜ P&ID(Piping and Instrumentation Diagram) ì „ë¬¸ ì—”ì§€ë‹ˆì–´ì…ë‹ˆë‹¤.

**ì „ë¬¸ ë¶„ì•¼:**
- í™”í•™ê³µì • ì„¤ê³„ ë° ì œì–´ì‹œìŠ¤í…œ
- ê³„ì¸¡ê¸°ê¸° ë° ì œì–´ë£¨í”„ ë¶„ì„
- ê³µì • ì•ˆì „ ë° ì´ìƒìƒí™© ëŒ€ì‘
- P&ID ë„ë©´ í•´ì„ ë° ê²€í† 

**ì‘ë‹µ ìŠ¤íƒ€ì¼:**
- ê¸°ìˆ ì ìœ¼ë¡œ ì •í™•í•˜ê³  ì‹¤ë¬´ì ì¸ ì¡°ì–¸ ì œê³µ
- ì•ˆì „ì„ ìµœìš°ì„ ìœ¼ë¡œ ê³ ë ¤
- êµ¬ì²´ì ì¸ ê³„ì¸¡ê¸°ê¸° íƒœê·¸(FT, FC, PT ë“±) ì–¸ê¸‰
- í•„ìš”ì‹œ ì¶”ê°€ ê²€í† ì‚¬í•­ ì œì•ˆ

**ì‘ë‹µ êµ¬ì¡°:**
1. í•µì‹¬ ë‹µë³€ (ê°„ê²°í•˜ê³  ëª…í™•í•˜ê²Œ)
2. ê¸°ìˆ ì  ì„¸ë¶€ì‚¬í•­ (ê´€ë ¨ ê³„ì¸¡ê¸°ê¸°, ì œì–´ë¡œì§ ë“±)
3. ì•ˆì „ ê³ ë ¤ì‚¬í•­ (í•´ë‹¹ë˜ëŠ” ê²½ìš°)
4. ì¶”ê°€ ê¶Œì¥ì‚¬í•­ (í•„ìš”í•œ ê²½ìš°)"""

    def save_state(self, chunks, embeddings):
        """ì²­í¬ì™€ ì„ë² ë”©ì„ pickleë¡œ ì €ì¥"""
        os.makedirs(self.STATE_PATH, exist_ok=True)
        try:
            with open(os.path.join(self.STATE_PATH, "state.pkl"), "wb") as f:
                pickle.dump({"chunks": chunks, "embeddings": embeddings}, f)
            logger.info("ë²¡í„° ë°ì´í„°ë² ì´ìŠ¤ ì €ì¥ ì™„ë£Œ")
        except Exception as e:
            logger.error(f"ìƒíƒœ ì €ì¥ ì‹¤íŒ¨: {e}")

    def load_state(self):
        """ì €ì¥ëœ ì²­í¬ì™€ ì„ë² ë”©ì„ pickleë¡œ ë¡œë“œ"""
        state_file = os.path.join(self.STATE_PATH, "state.pkl")
        if os.path.exists(state_file):
            try:
                with open(state_file, "rb") as f:
                    data = pickle.load(f)
                    return data["chunks"], data["embeddings"]
            except Exception as e:
                logger.error(f"ìƒíƒœ ë¡œë“œ ì‹¤íŒ¨: {e}")
        return None, None

    def create_embeddings(self, chunks):
        """ì²­í¬ë“¤ì„ ì„ë² ë”©í•˜ì—¬ í…ì„œë¡œ ë³€í™˜"""
        embeddings = self.embedder.encode(chunks, convert_to_tensor=True)
        return embeddings

    def initialize_rag_system(self, pdf_path: str) -> bool:
        """RAG ì‹œìŠ¤í…œ ì´ˆê¸°í™”"""
        try:
            logger.info("RAG ì‹œìŠ¤í…œ ì´ˆê¸°í™” ì¤‘...")
            
            # ê¸°ì¡´ ìƒíƒœ ë¡œë“œ ì‹œë„
            chunks, embeddings = self.load_state()
            
            if chunks is None or embeddings is None:
                logger.info("ìƒˆë¡œìš´ ë²¡í„° ë°ì´í„°ë² ì´ìŠ¤ êµ¬ì¶• ì¤‘...")
                
                # PDF ë¡œë“œ ë° ì²­í‚¹
                if not os.path.exists(pdf_path):
                    logger.error(f"PDF íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {pdf_path}")
                    return False
                
                documents = self.kiwi_rag.extract_text_from_pdf(pdf_path)
                
                if not documents:
                    logger.error("PDF ë¬¸ì„œ ì¶”ì¶œ ì‹¤íŒ¨")
                    return False
                
                # ì²­í‚¹
                chunks_metadata = self.kiwi_rag.chunk_documents_with_kiwi(documents)
                chunks = [chunk['content'] for chunk in chunks_metadata]
                
                # ì„ë² ë”© ìƒì„±
                logger.info("ì„ë² ë”© ìƒì„± ì¤‘...")
                embeddings = self.create_embeddings(chunks)
                
                # ìƒíƒœ ì €ì¥
                self.save_state(chunks, embeddings)
            else:
                logger.info("ê¸°ì¡´ ë²¡í„° ë°ì´í„°ë² ì´ìŠ¤ ë¡œë“œ ì™„ë£Œ")
            
            self.chunks = chunks
            self.embeddings = embeddings
            
            logger.info(f"RAG ì‹œìŠ¤í…œ ì¤€ë¹„ ì™„ë£Œ: {len(chunks)}ê°œ ì²­í¬, {embeddings.shape} ì„ë² ë”©")
            return True
            
        except Exception as e:
            logger.error(f"RAG ì‹œìŠ¤í…œ ì´ˆê¸°í™” ì‹¤íŒ¨: {e}")
            return False

    def retrieve_relevant_chunks(self, query, top_k=3):
        """RAG ê²€ìƒ‰ - ê´€ë ¨ ì²­í¬ ì¶”ì¶œ"""
        if self.chunks is None or self.embeddings is None:
            return []
        
        try:
            # ì¿¼ë¦¬ ì„ë² ë”© ìƒì„±
            query_embedding = self.embedder.encode(query, convert_to_tensor=True)
            query_embedding = query_embedding / torch.norm(query_embedding)
            
            # ì„ë² ë”© ì •ê·œí™”
            embeddings_norm = self.embeddings / torch.norm(self.embeddings, dim=1, keepdim=True)
            
            # ìœ ì‚¬ë„ ê³„ì‚°
            similarities = torch.matmul(embeddings_norm, query_embedding)
            
            # ìƒìœ„ kê°œ ì¶”ì¶œ
            top_k_indices = torch.topk(similarities, min(top_k, len(similarities))).indices.tolist()
            top_k_scores = torch.topk(similarities, min(top_k, len(similarities))).values.tolist()
            
            # ê´€ë ¨ ì²­í¬ì™€ ì ìˆ˜ ë°˜í™˜
            relevant_chunks = []
            for i, (idx, score) in enumerate(zip(top_k_indices, top_k_scores)):
                relevant_chunks.append({
                    'content': self.chunks[idx],
                    'score': score,
                    'rank': i + 1,
                    'page': i + 1  # Streamlit í˜¸í™˜ì„±ì„ ìœ„í•´ í˜ì´ì§€ ë²ˆí˜¸ ì¶”ê°€
                })
            
            return relevant_chunks
            
        except Exception as e:
            logger.error(f"RAG ê²€ìƒ‰ ì‹¤íŒ¨: {e}")
            return []

    def build_rag_context(self, relevant_chunks):
        """RAG ê²€ìƒ‰ ê²°ê³¼ë¥¼ ì»¨í…ìŠ¤íŠ¸ë¡œ êµ¬ì„±"""
        context = ""
        for chunk in relevant_chunks:
            context += f"[ì°¸ê³ ìë£Œ {chunk['rank']}] (ìœ ì‚¬ë„: {chunk['score']:.3f})\n"
            context += f"{chunk['content']}\n\n"
        return context.strip()

    def create_pid_expert_prompt(self, user_question, rag_context):
        """P&ID ì „ë¬¸ê°€ í˜ë¥´ì†Œë‚˜ í”„ë¡¬í”„íŠ¸ ìƒì„±"""
        
        system_prompt = f"""{self.expert_persona}

**ì°¸ê³  ë¬¸ì„œ ì •ë³´:**
{rag_context}

ìœ„ ì°¸ê³  ë¬¸ì„œë¥¼ ë°”íƒ•ìœ¼ë¡œ ì‚¬ìš©ìì˜ ì§ˆë¬¸ì— ì „ë¬¸ì ì´ê³  ì‹¤ìš©ì ì¸ ë‹µë³€ì„ ì œê³µí•´ì£¼ì„¸ìš”.
ì°¸ê³  ë¬¸ì„œì— ì—†ëŠ” ë‚´ìš©ì€ ì¼ë°˜ì ì¸ P&ID ì§€ì‹ì„ í™œìš©í•˜ë˜, ì¶”ì¸¡ì´ ì•„ë‹Œ í™•ì‹¤í•œ ì •ë³´ë§Œ ì œê³µí•˜ì„¸ìš”."""

        return system_prompt

    def _detect_query_type(self, query: str) -> str:
        """ì¿¼ë¦¬ ìœ í˜• ê°ì§€ - ë„ë©´ ê²€ìƒ‰ ê¸°ëŠ¥ ì¶”ê°€"""
        
        # ë„ë©´ ì‹œê°í™” ê´€ë ¨ í‚¤ì›Œë“œ í™•ì¸
        visualization_keywords = [
            'ë¶„ì„í•´ì¤˜', 'ì‹œê°í™”', 'ê·¸ë ¤ì¤˜', 'ë³´ì—¬ì¤˜', 'í‘œì‹œí•´ì¤˜', 
            'ocr', 'detection', 'ë°”ìš´ë”©', 'ë°•ìŠ¤', 'ë„¤ëª¨'
        ]
        
        # ë„ë©´ ê²€ìƒ‰ ê´€ë ¨ í‚¤ì›Œë“œ í™•ì¸
        drawing_search_keywords = [
            'ë„ë©´', 'íŒŒì¼', 'ê·¸ë¦¼', 'pdf', 'stream', 'does', 'ai',
            'ì°¾ì•„', 'ê²€ìƒ‰', 'ë³´ì—¬', 'ì•Œë ¤', 'ì–´ë””', 'ìˆë‚˜', 'ë¬´ì—‡'
        ]
        
        # ë‚´ë¶€/ê¸°ë°€ ë°ì´í„° ê´€ë ¨ í‚¤ì›Œë“œ (ì›¹ ê²€ìƒ‰ ê¸ˆì§€)
        internal_keywords = [
            'ê³µì •', 'ì‹œìŠ¤í…œ', 'ìš”ì•½', 'ë¶„ì„', 'ë„ë©´', 'ì„¤ê³„', 'ìš´ì „', 'ì œì–´',
            'í”„ë¡œì„¸ìŠ¤', 'ì„¤ë¹„',
            'ì ˆì°¨', 'ë§¤ë‰´ì–¼', 'ì‚¬ì–‘', 'ê·œê²©'
        ]
        
        # ë³€ê²½/ë¹„êµ ê´€ë ¨ í‚¤ì›Œë“œ (ë” ì •í™•í•œ ê°ì§€)
        change_keywords = [
            'ë³€ê²½', 'ì°¨ì´', 'ë¹„êµ', 'ìˆ˜ì •', 'ê°œì„ ', 'ì—…ë°ì´íŠ¸', 'ë°”ë€', 'ë‹¬ë¼ì§„',
            'ì´ì „', 'ê¸°ì¡´', 'ì›ë˜', 'ìƒˆë¡œìš´', 'ë³€í™”', 'ë‹¤ë¥¸ì ', 'ì°¨ì´ì ',
            'ê°œì •', 'ìˆ˜ì •ì‚¬í•­', 'ë³€ê²½ì‚¬í•­', 'ì—…ê·¸ë ˆì´ë“œ', 'êµì²´', 'êµí™˜',
            'ì „í›„', 'ë³€ë™', 'ì¡°ì •', 'ê°œëŸ‰', 'ê°œì„ ì‚¬í•­'
        ]
        
        # ë¹„êµ í‘œí˜„ íŒ¨í„´
        comparison_patterns = [
            r'vs|versus',  # A vs B
            r'ì™€\s*ë¹„êµ',  # Aì™€ ë¹„êµ
            r'ê³¼\s*ë¹„êµ',  # Aê³¼ ë¹„êµ
            r'ëŒ€ë¹„',       # A ëŒ€ë¹„ B
            r'ì—ì„œ\s*.*ë¡œ',  # Aì—ì„œ Bë¡œ
            r'ê¸°ì¡´.*ìƒˆë¡œìš´',  # ê¸°ì¡´ A ìƒˆë¡œìš´ B
            r'ì´ì „.*í˜„ì¬',   # ì´ì „ A í˜„ì¬ B
        ]
        
        safety_keywords = ['ì•ˆì „', 'ìœ„í—˜', 'ë¹„ìƒ', 'ì •ì§€', 'ë³´í˜¸', 'ì•ŒëŒ', 'ESD', 'SIS', 'ì¸í„°ë¡']
        instrument_keywords = ['FT', 'FC', 'FV', 'PT', 'PC', 'TT', 'TC', 'LT', 'LC', 'AT', 'AC', 'ê³„ì¸¡ê¸°', 'íŠ¸ëœìŠ¤ë¯¸í„°', 'ì¡°ì ˆê¸°']
        
        query_lower = query.lower()
        
        # ë„ë©´ ì‹œê°í™” í‚¤ì›Œë“œ ìš°ì„  í™•ì¸ (ë„ë©´ëª…ê³¼ í•¨ê»˜ ì‚¬ìš©ëœ ê²½ìš°)
        has_drawing_ref = any(keyword in query for keyword in drawing_search_keywords)
        has_viz_request = any(keyword in query for keyword in visualization_keywords)
        
        if has_drawing_ref and has_viz_request:
            # ë„ë©´ ì´ë¦„ í›„ë³´ê°€ ìˆëŠ”ì§€ í™•ì¸
            drawing_candidates = self.extract_drawing_names_from_query(query)
            if drawing_candidates:
                return "drawing_visualization"
        
        # ë„ë©´ ê²€ìƒ‰ í‚¤ì›Œë“œ í™•ì¸
        if any(keyword in query for keyword in drawing_search_keywords):
            # ë„ë©´ ì´ë¦„ í›„ë³´ê°€ ìˆëŠ”ì§€ í™•ì¸
            drawing_candidates = self.extract_drawing_names_from_query(query)
            if drawing_candidates:
                return "drawing_search"
        
        # ë‚´ë¶€ ë°ì´í„° í‚¤ì›Œë“œ í™•ì¸ (ì›¹ ê²€ìƒ‰ ê¸ˆì§€)
        if any(keyword in query for keyword in internal_keywords):
            return "internal_data"
        
        # ë³€ê²½/ë¹„êµ í‚¤ì›Œë“œ í™•ì¸
        if any(keyword in query for keyword in change_keywords):
            return "change_analysis"
        
        # ë¹„êµ íŒ¨í„´ í™•ì¸
        import re
        for pattern in comparison_patterns:
            if re.search(pattern, query):
                return "change_analysis"
        
        # ê¸°íƒ€ ë¶„ë¥˜
        if any(keyword in query for keyword in safety_keywords):
            return "safety_analysis"
        elif any(keyword in query for keyword in instrument_keywords):
            return "instrument_explanation"
        else:
            return "general"

    def create_change_analysis_prompt(self, user_question, rag_context):
        """ë³€ê²½ ë¶„ì„ ì „ìš© í”„ë¡¬í”„íŠ¸ ìƒì„± - ë°ì´í„°ë² ì´ìŠ¤ ë„ë©´ ë°ì´í„° í¬í•¨"""
        
        change_expert_persona = """ë‹¹ì‹ ì€ 20ë…„ ê²½ë ¥ì˜ P&ID ë³€ê²½ ê´€ë¦¬ ì „ë¬¸ê°€ì…ë‹ˆë‹¤.

**ì „ë¬¸ ë¶„ì•¼:**
- P&ID ë„ë©´ ë³€ê²½ì‚¬í•­ ë¶„ì„ ë° ê²€í† 
- ê³µì • ê°œì„  ë° ì„¤ë¹„ êµì²´ ì˜í–¥ ë¶„ì„
- ë³€ê²½ ì „í›„ ë¹„êµ ë¶„ì„
- ë³€ê²½ì‚¬í•­ì˜ ì•ˆì „ì„± ë° ìš´ì „ì„± í‰ê°€

**ë³€ê²½ ë¶„ì„ ì ‘ê·¼ë²•:**
1. **ë³€ê²½ ì‚¬í•­ ì‹ë³„**: ì •í™•íˆ ë¬´ì—‡ì´ ë³€ê²½ë˜ì—ˆëŠ”ì§€ íŒŒì•…
2. **ì˜í–¥ë„ ë¶„ì„**: ë³€ê²½ì´ ì£¼ë³€ ì‹œìŠ¤í…œì— ë¯¸ì¹˜ëŠ” ì˜í–¥
3. **ì•ˆì „ì„± ê²€í† **: ë³€ê²½ìœ¼ë¡œ ì¸í•œ ì•ˆì „ ë¦¬ìŠ¤í¬ í‰ê°€
4. **ìš´ì „ì„± ê²€í† **: ìš´ì „ ì ˆì°¨ ë° ìœ ì§€ë³´ìˆ˜ì— ë¯¸ì¹˜ëŠ” ì˜í–¥
5. **ê¶Œì¥ì‚¬í•­**: ë³€ê²½ ì‹œ ê³ ë ¤í•´ì•¼ í•  ì¶”ê°€ ì‚¬í•­

**ë‹µë³€ êµ¬ì¡°:**
1. **ë³€ê²½ì‚¬í•­ ìš”ì•½** (ë¬´ì—‡ì´ ì–´ë–»ê²Œ ë°”ë€Œì—ˆëŠ”ì§€)
2. **ê¸°ìˆ ì  ì˜í–¥ ë¶„ì„** (ì‹œìŠ¤í…œì— ë¯¸ì¹˜ëŠ” ì˜í–¥)
3. **ì•ˆì „ì„± ê²€í† ** (ì•ˆì „ ê´€ë ¨ ê³ ë ¤ì‚¬í•­)
4. **ìš´ì „ ë° ìœ ì§€ë³´ìˆ˜ ì˜í–¥** (ì‹¤ë¬´ì  ê³ ë ¤ì‚¬í•­)
5. **ê¶Œì¥ì‚¬í•­ ë° ì£¼ì˜ì‚¬í•­** (ì¶”ê°€ ê²€í†  í•„ìš” ì‚¬í•­)"""

        # ì‚¬ìš©ì ì§ˆë¬¸ì—ì„œ íŒŒì¼ëª… ì¶”ì¶œ ì‹œë„
        drawing_context = ""
        
        try:
            # ì§ˆë¬¸ì—ì„œ íŒŒì¼ëª… íŒ¨í„´ ì°¾ê¸°
            import re
            
            # íŒŒì¼ëª… íŒ¨í„´ë“¤ (í™•ì¥ì í¬í•¨)
            file_patterns = [
                r'([a-zA-Z0-9ê°€-í£_\-\.]+\.(?:pdf|png|jpg|jpeg))',  # í™•ì¥ì í¬í•¨
                r'([a-zA-Z0-9ê°€-í£_\-\.]+)\s*(?:íŒŒì¼|ë„ë©´|ë¬¸ì„œ)',    # íŒŒì¼/ë„ë©´/ë¬¸ì„œ í‚¤ì›Œë“œ
                r'"([^"]+)"',  # ë”°ì˜´í‘œë¡œ ê°ì‹¼ íŒŒì¼ëª…
                r"'([^']+)'"   # ì‘ì€ë”°ì˜´í‘œë¡œ ê°ì‹¼ íŒŒì¼ëª…
            ]
            
            detected_filename = None
            for pattern in file_patterns:
                matches = re.findall(pattern, user_question, re.IGNORECASE)
                if matches:
                    detected_filename = matches[0]
                    break
            
            if detected_filename:
                logger.info(f"ì§ˆë¬¸ì—ì„œ íŒŒì¼ëª… ê°ì§€: {detected_filename}")
                
                # ë³€ê²½ ê´€ë ¨ í‚¤ì›Œë“œ í™•ì¸
                change_keywords = ['ë³€ê²½', 'ìˆ˜ì •', 'ê°œì„ ', 'êµì²´', 'ì—…ê·¸ë ˆì´ë“œ', 'ì¡°ì •', 'ë¹„êµ', 'ì°¨ì´', 'ì „í›„']
                version_keywords = {
                    'latest': ['ìµœì‹ ', 'ìƒˆë¡œìš´', 'í˜„ì¬', 'ì—…ë°ì´íŠ¸ëœ', 'ì‹ ê·œ'],
                    'previous': ['ì´ì „', 'ê³¼ê±°', 'ì›ë˜', 'ê¸°ì¡´', 'ì˜›ë‚ ']
                }
                
                is_change_analysis = any(keyword in user_question for keyword in change_keywords)
                
                if is_change_analysis:
                    # ìµœì‹  ë²„ì „ê³¼ ì´ì „ ë²„ì „ ëª¨ë‘ ì¡°íšŒ
                    latest_data = self.get_drawing_data_from_db(detected_filename, "latest")
                    previous_data = self.get_drawing_data_from_db(detected_filename, "previous")
                    
                    if latest_data or previous_data:
                        drawing_context = "\n\n=== ë°ì´í„°ë² ì´ìŠ¤ì—ì„œ ì¡°íšŒëœ ë„ë©´ ì •ë³´ ===\n"
                        
                        if latest_data:
                            drawing_context += self.build_drawing_context(latest_data, "ìµœì‹ ")
                            drawing_context += "\n\n"
                        
                        if previous_data:
                            drawing_context += self.build_drawing_context(previous_data, "ì´ì „")
                            drawing_context += "\n\n"
                        
                        # ë¹„êµ ë¶„ì„ì„ ìœ„í•œ ì¶”ê°€ ì •ë³´
                        if latest_data and previous_data:
                            drawing_context += "=== ë²„ì „ ë¹„êµ ì •ë³´ ===\n"
                            drawing_context += f"ìµœì‹  ë²„ì „ ë“±ë¡ì¼: {latest_data.get('create_date')}\n"
                            drawing_context += f"ì´ì „ ë²„ì „ ë“±ë¡ì¼: {previous_data.get('create_date')}\n"
                            
                            # í…ìŠ¤íŠ¸ ë³€ê²½ ë¶„ì„
                            latest_text = self.extract_text_from_drawing_data(latest_data)
                            previous_text = self.extract_text_from_drawing_data(previous_data)
                            
                            if latest_text != previous_text:
                                drawing_context += "âš ï¸ ë„ë©´ í…ìŠ¤íŠ¸ ë‚´ìš©ì— ë³€ê²½ì‚¬í•­ì´ ê°ì§€ë˜ì—ˆìŠµë‹ˆë‹¤.\n"
                            else:
                                drawing_context += "â„¹ï¸ ë„ë©´ í…ìŠ¤íŠ¸ ë‚´ìš©ì—ëŠ” ë³€ê²½ì‚¬í•­ì´ ì—†ìŠµë‹ˆë‹¤.\n"
                    else:
                        drawing_context += f"\n\nâš ï¸ '{detected_filename}' íŒŒì¼ì„ ë°ì´í„°ë² ì´ìŠ¤ì—ì„œ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.\n"
                
                else:
                    # ë³€ê²½ ë¶„ì„ì´ ì•„ë‹Œ ê²½ìš° íŠ¹ì • ë²„ì „ ìš”ì²­ í™•ì¸
                    requested_version = "latest"  # ê¸°ë³¸ê°’
                    
                    for version, keywords in version_keywords.items():
                        if any(keyword in user_question for keyword in keywords):
                            requested_version = version
                            break
                    
                    drawing_data = self.get_drawing_data_from_db(detected_filename, requested_version)
                    
                    if drawing_data:
                        version_label = "ìµœì‹ " if requested_version == "latest" else "ì´ì „"
                        drawing_context = "\n\n=== ë°ì´í„°ë² ì´ìŠ¤ì—ì„œ ì¡°íšŒëœ ë„ë©´ ì •ë³´ ===\n"
                        drawing_context += self.build_drawing_context(drawing_data, version_label)
                    else:
                        drawing_context += f"\n\nâš ï¸ '{detected_filename}' ({requested_version})ì„ ë°ì´í„°ë² ì´ìŠ¤ì—ì„œ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.\n"
            
        except Exception as e:
            logger.error(f"ë°ì´í„°ë² ì´ìŠ¤ ì¡°íšŒ ì¤‘ ì˜¤ë¥˜: {e}")
            drawing_context = "\n\nâš ï¸ ë°ì´í„°ë² ì´ìŠ¤ ì¡°íšŒ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤.\n"

        # ì „ì²´ í”„ë¡¬í”„íŠ¸ êµ¬ì„±
        system_prompt = f"""{change_expert_persona}

**ì°¸ê³  ë¬¸ì„œ ì •ë³´:**
{rag_context}

**ë„ë©´ ë°ì´í„°ë² ì´ìŠ¤ ì •ë³´:**
{drawing_context}

ì‚¬ìš©ìê°€ P&ID ë³€ê²½ ë˜ëŠ” ë¹„êµì— ëŒ€í•´ ì§ˆë¬¸í–ˆìŠµë‹ˆë‹¤. ë³€ê²½ ê´€ë¦¬ ì „ë¬¸ê°€ë¡œì„œ ë‹¤ìŒ ì‚¬í•­ì„ ì¤‘ì ì ìœ¼ë¡œ ë¶„ì„í•´ì£¼ì„¸ìš”:

- ë³€ê²½ì‚¬í•­ì˜ êµ¬ì²´ì  ë‚´ìš©ê³¼ ë²”ìœ„
- ì—°ê´€ ì‹œìŠ¤í…œì— ë¯¸ì¹˜ëŠ” ì˜í–¥
- ì•ˆì „ì„± ë° ìš´ì „ì„± ê´€ì ì—ì„œì˜ ê²€í† 
- ë³€ê²½ ì‹œ ì¶”ê°€ ê³ ë ¤í•´ì•¼ í•  ì‚¬í•­

ìœ„ ì°¸ê³  ë¬¸ì„œì™€ ë°ì´í„°ë² ì´ìŠ¤ì—ì„œ ì¡°íšŒëœ ë„ë©´ ì •ë³´ë¥¼ ë°”íƒ•ìœ¼ë¡œ ì „ë¬¸ì ì´ê³  ì²´ê³„ì ì¸ ë³€ê²½ ë¶„ì„ì„ ì œê³µí•´ì£¼ì„¸ìš”.

íŒŒì¼ëª…ì´ ê°ì§€ë˜ì—ˆë‹¤ë©´ í•´ë‹¹ ë„ë©´ì˜ ì‹¤ì œ ë°ì´í„°ë¥¼ ìš°ì„ ì ìœ¼ë¡œ ì°¸ê³ í•˜ì—¬ ë‹µë³€í•˜ì„¸ìš”."""

        return system_prompt

    def retrieve_change_analysis_chunks(self, query, top_k=5):
        """ë³€ê²½ ë¶„ì„ì„ ìœ„í•œ í™•ì¥ëœ ê²€ìƒ‰"""
        if self.chunks is None or self.embeddings is None:
            return []
        
        try:
            # ê¸°ë³¸ ê²€ìƒ‰
            basic_chunks = self.retrieve_relevant_chunks(query, top_k=3)
            
            # ë³€ê²½ ê´€ë ¨ í‚¤ì›Œë“œë¡œ ì¶”ê°€ ê²€ìƒ‰
            change_terms = ['ë³€ê²½', 'ìˆ˜ì •', 'ê°œì„ ', 'êµì²´', 'ì—…ê·¸ë ˆì´ë“œ', 'ì¡°ì •']
            additional_chunks = []
            
            for term in change_terms:
                if term not in query:  # ì´ë¯¸ í¬í•¨ëœ ìš©ì–´ëŠ” ì œì™¸
                    expanded_query = f"{query} {term}"
                    extra_chunks = self.retrieve_relevant_chunks(expanded_query, top_k=2)
                    additional_chunks.extend(extra_chunks)
            
            # ì¤‘ë³µ ì œê±° ë° í†µí•©
            all_chunks = basic_chunks + additional_chunks
            seen_contents = set()
            unique_chunks = []
            
            for chunk in all_chunks:
                if chunk['content'] not in seen_contents:
                    seen_contents.add(chunk['content'])
                    unique_chunks.append(chunk)
            
            # ìƒìœ„ top_kê°œ ë°˜í™˜
            return unique_chunks[:top_k]
            
        except Exception as e:
            logger.error(f"ë³€ê²½ ë¶„ì„ ê²€ìƒ‰ ì‹¤íŒ¨: {e}")
            return self.retrieve_relevant_chunks(query, top_k)

    def get_drawing_data_from_db(self, d_name: str, version: str = "latest") -> Optional[Dict]:
        """
        ë°ì´í„°ë² ì´ìŠ¤ì—ì„œ ë„ë©´ ë°ì´í„°ë¥¼ ì¡°íšŒ
        
        Args:
            d_name: ë„ë©´ íŒŒì¼ëª…
            version: "latest" (ìµœì‹ ) ë˜ëŠ” "previous" (ì´ì „)
        
        Returns:
            ë„ë©´ ë°ì´í„° ë˜ëŠ” None
        """
        try:
            conn = get_db_connection()
            if not conn:
                logger.error("ë°ì´í„°ë² ì´ìŠ¤ ì—°ê²° ì‹¤íŒ¨")
                return None
            
            cursor = conn.cursor()
            
            if version == "latest":
                # ìµœì‹  íŒŒì¼ (create_dateê°€ ê°€ì¥ ëŠ¦ì€ ê²ƒ)
                query = """
                SELECT d_id, d_name, "user", create_date, json_data, image_path
                FROM domyun 
                WHERE d_name = %s 
                ORDER BY create_date DESC 
                LIMIT 1
                """
            else:  # previous
                # ì´ì „ íŒŒì¼ (create_dateê°€ ë‘ ë²ˆì§¸ë¡œ ëŠ¦ì€ ê²ƒ)
                query = """
                SELECT d_id, d_name, "user", create_date, json_data, image_path
                FROM domyun 
                WHERE d_name = %s 
                ORDER BY create_date DESC 
                LIMIT 1 OFFSET 1
                """
            
            cursor.execute(query, (d_name,))
            result = cursor.fetchone()
            
            cursor.close()
            conn.close()
            
            if result:
                d_id, d_name, user, create_date, json_data, image_path = result
                return {
                    'd_id': d_id,
                    'd_name': d_name,
                    'user': user,
                    'create_date': create_date,
                    'json_data': json_data,
                    'image_path': image_path
                }
            else:
                logger.warning(f"ë„ë©´ '{d_name}' ({version})ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤")
                return None
                
        except Exception as e:
            logger.error(f"ë°ì´í„°ë² ì´ìŠ¤ ì¡°íšŒ ì‹¤íŒ¨: {e}")
            return None

    def get_all_versions_of_drawing(self, d_name: str) -> List[Dict]:
        """
        íŠ¹ì • ë„ë©´ì˜ ëª¨ë“  ë²„ì „ì„ ì¡°íšŒ
        
        Args:
            d_name: ë„ë©´ íŒŒì¼ëª…
        
        Returns:
            ëª¨ë“  ë²„ì „ì˜ ë„ë©´ ë°ì´í„° ë¦¬ìŠ¤íŠ¸ (ìµœì‹ ìˆœ)
        """
        try:
            conn = get_db_connection()
            if not conn:
                logger.error("ë°ì´í„°ë² ì´ìŠ¤ ì—°ê²° ì‹¤íŒ¨")
                return []
            
            cursor = conn.cursor()
            
            query = """
            SELECT d_id, d_name, "user", create_date, json_data, image_path
            FROM domyun 
            WHERE d_name = %s 
            ORDER BY create_date DESC
            """
            
            cursor.execute(query, (d_name,))
            results = cursor.fetchall()
            
            cursor.close()
            conn.close()
            
            versions = []
            for result in results:
                d_id, d_name, user, create_date, json_data, image_path = result
                versions.append({
                    'd_id': d_id,
                    'd_name': d_name,
                    'user': user,
                    'create_date': create_date,
                    'json_data': json_data,
                    'image_path': image_path
                })
            
            return versions
                
        except Exception as e:
            logger.error(f"ë°ì´í„°ë² ì´ìŠ¤ ì¡°íšŒ ì‹¤íŒ¨: {e}")
            return []

    def extract_text_from_drawing_data(self, drawing_data: Dict) -> str:
        """
        ë„ë©´ ë°ì´í„°ì—ì„œ í…ìŠ¤íŠ¸ë¥¼ ì¶”ì¶œ
        
        Args:
            drawing_data: ë°ì´í„°ë² ì´ìŠ¤ì—ì„œ ê°€ì ¸ì˜¨ ë„ë©´ ë°ì´í„°
        
        Returns:
            ì¶”ì¶œëœ í…ìŠ¤íŠ¸
        """
        if not drawing_data or not drawing_data.get('json_data'):
            return ""
        
        try:
            json_data = drawing_data['json_data']
            extracted_texts = []
            
            # OCR ë°ì´í„°ì—ì„œ í…ìŠ¤íŠ¸ ì¶”ì¶œ
            if 'ocr_data' in json_data and json_data['ocr_data']:
                ocr_data = json_data['ocr_data']
                if 'images' in ocr_data:
                    for image in ocr_data['images']:
                        if 'fields' in image:
                            for field in image['fields']:
                                if 'inferText' in field:
                                    extracted_texts.append(field['inferText'])
            
            # Detection ë°ì´í„°ì—ì„œ í…ìŠ¤íŠ¸ ì¶”ì¶œ (ìˆë‹¤ë©´)
            if 'detection_data' in json_data and json_data['detection_data']:
                detection_data = json_data['detection_data']
                if 'detections' in detection_data:
                    for detection in detection_data['detections']:
                        if 'text' in detection:
                            extracted_texts.append(detection['text'])
            
            return '\n'.join(extracted_texts)
            
        except Exception as e:
            logger.error(f"í…ìŠ¤íŠ¸ ì¶”ì¶œ ì‹¤íŒ¨: {e}")
            return ""

    def build_drawing_context(self, drawing_data: Dict, version_label: str = "") -> str:
        """
        ë„ë©´ ë°ì´í„°ë¥¼ ì»¨í…ìŠ¤íŠ¸ ë¬¸ìì—´ë¡œ êµ¬ì„±
        
        Args:
            drawing_data: ë„ë©´ ë°ì´í„°
            version_label: ë²„ì „ ë¼ë²¨ (ì˜ˆ: "ìµœì‹ ", "ì´ì „")
        
        Returns:
            êµ¬ì„±ëœ ì»¨í…ìŠ¤íŠ¸ ë¬¸ìì—´
        """
        if not drawing_data:
            return ""
        
        context_parts = []
        
        # ë„ë©´ ê¸°ë³¸ ì •ë³´
        context_parts.append(f"=== {version_label} ë„ë©´ ì •ë³´ ===")
        context_parts.append(f"íŒŒì¼ëª…: {drawing_data.get('d_name', 'N/A')}")
        context_parts.append(f"ë“±ë¡ì¼: {drawing_data.get('create_date', 'N/A')}")
        context_parts.append(f"ë“±ë¡ì: {drawing_data.get('user', 'N/A')}")
        
        # ì¶”ì¶œëœ í…ìŠ¤íŠ¸
        extracted_text = self.extract_text_from_drawing_data(drawing_data)
        if extracted_text:
            context_parts.append(f"\n--- {version_label} ë„ë©´ì—ì„œ ì¶”ì¶œëœ í…ìŠ¤íŠ¸ ---")
            context_parts.append(extracted_text)
        
        # JSON ë°ì´í„° ìš”ì•½
        json_data = drawing_data.get('json_data')
        if json_data:
            context_parts.append(f"\n--- {version_label} ë„ë©´ ë©”íƒ€ë°ì´í„° ---")
            
            # ì´ë¯¸ì§€ í¬ê¸° ì •ë³´
            if 'width' in json_data and 'height' in json_data:
                context_parts.append(f"ì´ë¯¸ì§€ í¬ê¸°: {json_data['width']} x {json_data['height']}")
            
            # OCR í†µê³„
            if 'ocr_data' in json_data and json_data['ocr_data']:
                ocr_data = json_data['ocr_data']
                if 'images' in ocr_data:
                    text_count = 0
                    for image in ocr_data['images']:
                        if 'fields' in image:
                            text_count += len(image['fields'])
                    context_parts.append(f"OCR ì¶”ì¶œ í…ìŠ¤íŠ¸ ê°œìˆ˜: {text_count}ê°œ")
            
            # Detection í†µê³„
            if 'detection_data' in json_data and json_data['detection_data']:
                detection_data = json_data['detection_data']
                if 'detections' in detection_data:
                    detection_count = len(detection_data['detections'])
                    context_parts.append(f"ê°ì§€ëœ ê°ì²´ ê°œìˆ˜: {detection_count}ê°œ")
        
        return '\n'.join(context_parts)

    def generate_response(self, user_query: str, use_web_search: bool = False, selected_drawing: str = None) -> Dict:
        """ì±—ë´‡ ì‘ë‹µ ìƒì„± - ì§€ëŠ¥ì  ì†ŒìŠ¤ ì„ íƒ ì‹œìŠ¤í…œ"""
        try:
            # ì¿¼ë¦¬ ìœ í˜• ê°ì§€
            query_type = self._detect_query_type(user_query)
            
            # ë„ë©´ ê²€ìƒ‰ ì²˜ë¦¬
            search_results = []
            auto_selected_drawing = None
            
            if query_type == "drawing_search":
                logger.info(f"ğŸ” ë„ë©´ ê²€ìƒ‰ ëª¨ë“œë¡œ ì²˜ë¦¬: {user_query}")
                
                # ì§ˆë¬¸ì—ì„œ ë„ë©´ ì´ë¦„ í›„ë³´ ì¶”ì¶œ
                drawing_candidates = self.extract_drawing_names_from_query(user_query)
                
                for candidate in drawing_candidates:
                    results = self.search_drawings_by_name(candidate)
                    search_results.extend(results)
                
                # ì¤‘ë³µ ì œê±°
                unique_results = {}
                for result in search_results:
                    unique_results[result['d_name']] = result
                search_results = list(unique_results.values())
                
                # ê²€ìƒ‰ ê²°ê³¼ê°€ 1ê°œì¸ ê²½ìš° ìë™ ì„ íƒ
                if len(search_results) == 1:
                    auto_selected_drawing = search_results[0]['d_name']
                    logger.info(f"ğŸ¯ ìë™ ë„ë©´ ì„ íƒ: {auto_selected_drawing}")
                elif len(search_results) > 1:
                    # ê°€ì¥ ìµœê·¼ ìˆ˜ì •ëœ ë„ë©´ ìš°ì„  ì„ íƒ
                    latest_drawing = max(search_results, key=lambda x: x['latest_date'])
                    auto_selected_drawing = latest_drawing['d_name']
                    logger.info(f"ğŸ¯ ìµœì‹  ë„ë©´ ìë™ ì„ íƒ: {auto_selected_drawing}")
            
            elif query_type == "drawing_visualization":
                logger.info(f"ğŸ¨ ë„ë©´ ì‹œê°í™” ëª¨ë“œë¡œ ì²˜ë¦¬: {user_query}")
                
                # ì§ˆë¬¸ì—ì„œ ë„ë©´ ì´ë¦„ í›„ë³´ ì¶”ì¶œ
                drawing_candidates = self.extract_drawing_names_from_query(user_query)
                
                if drawing_candidates:
                    # ì²« ë²ˆì§¸ í›„ë³´ë¡œ ì‹œê°í™” ì‹œë„
                    candidate = drawing_candidates[0]
                    
                    # ë„ë©´ ê²€ìƒ‰í•˜ì—¬ ì¡´ì¬ í™•ì¸
                    candidate_results = self.search_drawings_by_name(candidate)
                    
                    if candidate_results:
                        # ìµœì‹  ë²„ì „ìœ¼ë¡œ ì‹œê°í™” ìˆ˜í–‰
                        auto_selected_drawing = candidate_results[0]['d_name']
                        logger.info(f"ğŸ¨ ì‹œê°í™” ëŒ€ìƒ ë„ë©´: {auto_selected_drawing}")
                        
                        # ì§ì ‘ ì‹œê°í™” ë¶„ì„ ìˆ˜í–‰
                        viz_result = self.analyze_drawing_with_visualization(auto_selected_drawing, user_query)
                        
                        # ì‹œê°í™”ê°€ ì„±ê³µí•œ ê²½ìš° ë°”ë¡œ ë°˜í™˜
                        if viz_result and viz_result.get('visualization'):
                            return viz_result
                        else:
                            # ì‹œê°í™” ì‹¤íŒ¨ ì‹œ ì¼ë°˜ ê²€ìƒ‰ìœ¼ë¡œ í´ë°±
                            search_results = candidate_results
                    else:
                        logger.warning(f"âš ï¸ ì‹œê°í™” ìš”ì²­ëœ ë„ë©´ '{candidate}'ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤")
            
            # ì„ íƒëœ ë„ë©´ ìš°ì„ ìˆœìœ„: ìë™ ê²€ìƒ‰ > ì‚¬ìš©ì ì„ íƒ
            final_selected_drawing = auto_selected_drawing or selected_drawing
            
            # RAG ê²€ìƒ‰ ìˆ˜í–‰
            if query_type == "change_analysis":
                logger.info(f"ğŸ”„ ë³€ê²½ ë¶„ì„ ëª¨ë“œë¡œ ì²˜ë¦¬: {user_query}")
                relevant_chunks = self.retrieve_change_analysis_chunks(user_query, top_k=5)
            else:
                relevant_chunks = self.retrieve_relevant_chunks(user_query, top_k=3)
            
            # ìœ ì‚¬ë„ ê¸°ë°˜ ì†ŒìŠ¤ ì„ íƒ ë¡œì§
            SIMILARITY_THRESHOLD = 0.4
            high_quality_chunks = []
            low_quality_chunks = []
            
            for chunk in relevant_chunks:
                if chunk['score'] >= SIMILARITY_THRESHOLD:
                    high_quality_chunks.append(chunk)
                else:
                    low_quality_chunks.append(chunk)
            
            # ì†ŒìŠ¤ ì •ë³´ êµ¬ì„±
            sources = []
            rag_context = ""
            web_search_used = False
            web_search_results = ""
            
            # ë„ë©´ ê²€ìƒ‰ ê²°ê³¼ ì†ŒìŠ¤ ì¶”ê°€
            if search_results:
                for result in search_results:
                    sources.append({
                        'type': 'drawing_search',
                        'icon': 'ğŸ”',
                        'source': f'ë„ë©´ ê²€ìƒ‰ ê²°ê³¼ - {result["d_name"]}',
                        'score': None,
                        'page': None,
                        'content_preview': f"ë²„ì „: {result['version_count']}ê°œ, ìµœì¢…ìˆ˜ì •: {result['latest_date']}, ë“±ë¡ì: {result['users']}",
                        'quality': 'high'
                    })
            
            # ì„ íƒëœ ë„ë©´ ì •ë³´ ì¶”ê°€
            drawing_context = ""
            if final_selected_drawing and final_selected_drawing != "ì„ íƒí•˜ì§€ ì•ŠìŒ":
                logger.info(f"ğŸ“„ ì„ íƒëœ ë„ë©´ ì •ë³´ í™œìš©: {final_selected_drawing}")
                
                try:
                    # ìµœì‹  ë²„ì „ì˜ ë„ë©´ ë°ì´í„° ì¡°íšŒ
                    drawing_data = self.get_drawing_data_from_db(final_selected_drawing, "latest")
                    
                    if drawing_data:
                        drawing_context = self.build_drawing_context(drawing_data, "ì„ íƒëœ ë„ë©´")
                        
                        # ë„ë©´ ì†ŒìŠ¤ ì •ë³´ ì¶”ê°€ (ì¤‘ë³µ ì²´í¬)
                        existing_drawing_sources = [s for s in sources if s.get('type') == 'database' and final_selected_drawing in s.get('source', '')]
                        
                        if not existing_drawing_sources:
                            sources.append({
                                'type': 'database',
                                'icon': 'ğŸ—„ï¸',
                                'source': f'ì„ íƒëœ ë„ë©´ - {final_selected_drawing}',
                                'score': None,
                                'page': None,
                                'content_preview': f"ë“±ë¡ì¼: {drawing_data.get('create_date')}, ë“±ë¡ì: {drawing_data.get('user')}",
                                'quality': 'high'
                            })
                        
                        logger.info(f"âœ… ì„ íƒëœ ë„ë©´ ë°ì´í„° ì¡°íšŒ ì„±ê³µ: {final_selected_drawing}")
                    else:
                        logger.warning(f"âš ï¸ ì„ íƒëœ ë„ë©´ ë°ì´í„° ì¡°íšŒ ì‹¤íŒ¨: {final_selected_drawing}")
                        drawing_context = f"\n\nâš ï¸ ì„ íƒëœ ë„ë©´ '{final_selected_drawing}'ì˜ ë°ì´í„°ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.\n"
                        
                except Exception as e:
                    logger.error(f"ì„ íƒëœ ë„ë©´ ì¡°íšŒ ì¤‘ ì˜¤ë¥˜: {e}")
                    drawing_context = f"\n\nâš ï¸ ì„ íƒëœ ë„ë©´ ì¡°íšŒ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {str(e)}\n"
            
            # ê³ í’ˆì§ˆ RAG ë°ì´í„°ê°€ ìˆëŠ” ê²½ìš°
            if high_quality_chunks:
                logger.info(f"ğŸ“– ê³ í’ˆì§ˆ RAG ë°ì´í„° {len(high_quality_chunks)}ê°œ ë°œê²¬ (ìœ ì‚¬ë„ â‰¥ {SIMILARITY_THRESHOLD})")
                
                rag_context = self.build_rag_context(high_quality_chunks)
                
                # RAG ì†ŒìŠ¤ ì •ë³´ ì¶”ê°€
                for chunk in high_quality_chunks:
                    sources.append({
                        'type': 'rag',
                        'icon': 'ğŸ“–',
                        'source': 'RAG ë°ì´í„°ë² ì´ìŠ¤',
                        'score': chunk['score'],
                        'page': chunk['page'],
                        'content_preview': chunk['content'][:200] + "..." if len(chunk['content']) > 200 else chunk['content'],
                        'quality': 'high'
                    })
                
                # ì €í’ˆì§ˆ ë°ì´í„°ë„ ìˆë‹¤ë©´ ì¶”ê°€ (ì°¸ê³ ìš©)
                if low_quality_chunks:
                    for chunk in low_quality_chunks:
                        sources.append({
                            'type': 'rag',
                            'icon': 'ğŸ“–',
                            'source': 'RAG ë°ì´í„°ë² ì´ìŠ¤ (ì°¸ê³ )',
                            'score': chunk['score'],
                            'page': chunk['page'],
                            'content_preview': chunk['content'][:200] + "..." if len(chunk['content']) > 200 else chunk['content'],
                            'quality': 'low'
                        })
            
            # ê³ í’ˆì§ˆ RAG ë°ì´í„°ê°€ ì—†ê±°ë‚˜ ë¶€ì¡±í•œ ê²½ìš° ì›¹ ê²€ìƒ‰ ì‹œë„
            # ë‹¨, internal_data íƒ€ì…ì€ ì›¹ ê²€ìƒ‰ ê¸ˆì§€
            if (not high_quality_chunks or len(high_quality_chunks) < 2) and query_type not in ["internal_data", "drawing_search"]:
                logger.info(f"ğŸŒ RAG ë°ì´í„° ë¶€ì¡± (ê³ í’ˆì§ˆ: {len(high_quality_chunks)}ê°œ) - ì›¹ ê²€ìƒ‰ ì‹œë„")
                
                try:
                    # GPTì—ê²Œ ì¸í„°ë„· ê²€ìƒ‰ ìš”ì²­
                    web_search_prompt = f"""ë‹¤ìŒ ì§ˆë¬¸ì— ëŒ€í•´ ìµœì‹  ì •ë³´ë¥¼ ì œê³µí•´ì£¼ì„¸ìš”. P&ID ë° ê³µì • ì œì–´ ê´€ë ¨ ê¸°ìˆ  ì •ë³´ë¥¼ í¬í•¨í•´ ì£¼ì„¸ìš”:

ì§ˆë¬¸: {user_query}

ë‹µë³€ ì‹œ ë‹¤ìŒì„ í¬í•¨í•´ ì£¼ì„¸ìš”:
1. ìµœì‹  ê¸°ìˆ  ë™í–¥
2. ê´€ë ¨ í‘œì¤€ ë° ê·œê²©
3. ì‹¤ë¬´ì  ì ìš© ì‚¬ë¡€
4. ì•ˆì „ ê³ ë ¤ì‚¬í•­

ë‹µë³€ ì¶œì²˜ë¥¼ ëª…ì‹œí•˜ì§€ ë§ê³ , ì „ë¬¸ì ì´ê³  ì¢…í•©ì ì¸ ì •ë³´ë¥¼ ì œê³µí•´ ì£¼ì„¸ìš”."""

                    web_response = self.client.chat.completions.create(
                        model="gpt-4o-mini",
                        messages=[
                            {"role": "system", "content": "ë‹¹ì‹ ì€ P&ID ë° ê³µì •ì œì–´ ì „ë¬¸ê°€ì…ë‹ˆë‹¤. ìµœì‹  ê¸°ìˆ  ì •ë³´ì™€ ì‹¤ë¬´ ì§€ì‹ì„ ë°”íƒ•ìœ¼ë¡œ ì •í™•í•œ ë‹µë³€ì„ ì œê³µí•˜ì„¸ìš”."},
                            {"role": "user", "content": web_search_prompt}
                        ],
                        temperature=0.3,
                        max_tokens=1000
                    )
                    
                    web_search_results = web_response.choices[0].message.content
                    web_search_used = True
                    
                    # ì›¹ ê²€ìƒ‰ ì†ŒìŠ¤ ì •ë³´ ì¶”ê°€
                    sources.append({
                        'type': 'web',
                        'icon': 'ğŸŒ',
                        'source': 'ì¸í„°ë„· ê²€ìƒ‰ (GPT-4 ê¸°ë°˜)',
                        'score': None,
                        'page': None,
                        'content_preview': web_search_results[:200] + "..." if len(web_search_results) > 200 else web_search_results,
                        'quality': 'web'
                    })
                    
                    logger.info("âœ… ì›¹ ê²€ìƒ‰ ì™„ë£Œ")
                    
                except Exception as e:
                    logger.error(f"ì›¹ ê²€ìƒ‰ ì‹¤íŒ¨: {e}")
                    web_search_results = ""
            elif query_type == "internal_data":
                logger.info(f"ğŸ”’ ë‚´ë¶€ ë°ì´í„° ì§ˆë¬¸ - ì›¹ ê²€ìƒ‰ ìŠ¤í‚µ (RAG ì „ìš©)")
            elif query_type == "drawing_search":
                logger.info(f"ğŸ” ë„ë©´ ê²€ìƒ‰ ì§ˆë¬¸ - ì›¹ ê²€ìƒ‰ ìŠ¤í‚µ (ë°ì´í„°ë² ì´ìŠ¤ ì „ìš©)")
            else:
                logger.info(f"ğŸ“– RAG ë°ì´í„° ì¶©ë¶„ (ê³ í’ˆì§ˆ: {len(high_quality_chunks)}ê°œ) - ì›¹ ê²€ìƒ‰ ë¶ˆí•„ìš”")
            
            # í”„ë¡¬í”„íŠ¸ ìƒì„±
            if query_type == "drawing_search":
                system_prompt = self.create_drawing_search_prompt(user_query, search_results, rag_context)
                max_tokens = 1800
                temperature = 0.2
            elif query_type == "change_analysis":
                system_prompt = self.create_change_analysis_prompt(user_query, rag_context)
                max_tokens = 2000
                temperature = 0.2
            elif query_type == "internal_data":
                system_prompt = self.create_internal_data_prompt(user_query, rag_context)
                max_tokens = 1800
                temperature = 0.1  # ë” ì¼ê´€ëœ ë‹µë³€ì„ ìœ„í•´ ë‚®ì€ temperature
            else:
                system_prompt = self.create_pid_expert_prompt(user_query, rag_context)
                max_tokens = 1500
                temperature = 0.3
            
            # ì„ íƒëœ ë„ë©´ ì •ë³´ê°€ ìˆìœ¼ë©´ ì‹œìŠ¤í…œ í”„ë¡¬í”„íŠ¸ì— ì¶”ê°€
            if drawing_context and query_type != "drawing_search":
                system_prompt += f"""

**ì„ íƒëœ ë„ë©´ ì •ë³´:**
{drawing_context}

ìœ„ ì„ íƒëœ ë„ë©´ ì •ë³´ë¥¼ ìš°ì„ ì ìœ¼ë¡œ ì°¸ê³ í•˜ì—¬ ë‹µë³€í•´ì£¼ì„¸ìš”. íŠ¹íˆ ì‚¬ìš©ìì˜ ì§ˆë¬¸ì´ ì´ ë„ë©´ê³¼ ê´€ë ¨ëœ ë‚´ìš©ì´ë¼ë©´ ë„ë©´ì˜ êµ¬ì²´ì ì¸ ë°ì´í„°ë¥¼ í™œìš©í•´ì£¼ì„¸ìš”."""
            
            # ì›¹ ê²€ìƒ‰ ê²°ê³¼ê°€ ìˆìœ¼ë©´ í”„ë¡¬í”„íŠ¸ì— ì¶”ê°€
            if web_search_results:
                system_prompt += f"""

**ì¶”ê°€ ìµœì‹  ì •ë³´ (ì›¹ ê²€ìƒ‰ ê²°ê³¼):**
{web_search_results}

ìœ„ ì›¹ ê²€ìƒ‰ ì •ë³´ë„ ì°¸ê³ í•˜ì—¬ ìµœì‹  ë™í–¥ê³¼ ì‹¤ë¬´ ì •ë³´ë¥¼ í¬í•¨í•œ ì¢…í•©ì ì¸ ë‹µë³€ì„ ì œê³µí•´ì£¼ì„¸ìš”."""

            # ì»¨í…ìŠ¤íŠ¸ í’ˆì§ˆ í‰ê°€
            if drawing_context or high_quality_chunks or search_results:
                context_quality = "high"
            elif low_quality_chunks or web_search_results:
                context_quality = "medium"
            else:
                context_quality = "low"
            
            # OpenAI API í˜¸ì¶œ
            if not self.client:
                return {
                    'response': "OpenAI API í‚¤ê°€ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤. .env íŒŒì¼ì„ í™•ì¸í•´ì£¼ì„¸ìš”.",
                    'sources': sources,
                    'query_type': query_type,
                    'context_quality': context_quality,
                    'web_search_used': web_search_used,
                    'similarity_threshold': SIMILARITY_THRESHOLD,
                    'selected_drawing': final_selected_drawing,
                    'search_results': search_results
                }
            
            try:
                response = self.client.chat.completions.create(
                    model="gpt-4o-mini",
                    messages=[
                        {"role": "system", "content": system_prompt},
                        {"role": "user", "content": user_query}
                    ],
                    temperature=temperature,
                    max_tokens=max_tokens
                )
                
                ai_response = response.choices[0].message.content
                
                # ì‘ë‹µì— ì†ŒìŠ¤ ì •ë³´ í‘œì‹œ ì¶”ê°€
                source_info = self._build_source_summary(sources, SIMILARITY_THRESHOLD)
                if source_info:
                    ai_response += f"\n\n{source_info}"
                
                # íŠ¹ë³„ ëª¨ë“œ í‘œì‹œ
                if query_type == "drawing_search":
                    ai_response = f"ğŸ” **ë„ë©´ ê²€ìƒ‰ ëª¨ë“œ** (ë°œê²¬: {len(search_results)}ê°œ)\n\n" + ai_response
                elif query_type == "change_analysis":
                    ai_response = "ğŸ”„ **ë³€ê²½ ë¶„ì„ ëª¨ë“œ**\n\n" + ai_response
                
                # ìë™ ì„ íƒëœ ë„ë©´ì´ ìˆëŠ” ê²½ìš° í‘œì‹œ
                if auto_selected_drawing:
                    ai_response = f"ğŸ¯ **ìë™ ì„ íƒëœ ë„ë©´: {auto_selected_drawing}**\n\n" + ai_response
                elif final_selected_drawing and final_selected_drawing != "ì„ íƒí•˜ì§€ ì•ŠìŒ":
                    ai_response = f"ğŸ“„ **ë¶„ì„ ê¸°ì¤€ ë„ë©´: {final_selected_drawing}**\n\n" + ai_response
                
            except Exception as e:
                logger.error(f"OpenAI API í˜¸ì¶œ ì‹¤íŒ¨: {e}")
                ai_response = f"OpenAI API ì˜¤ë¥˜: {e}"
            
            # ëŒ€í™” ê¸°ë¡ ì €ì¥
            self.conversation_history.append({
                'timestamp': datetime.now(),
                'user_query': user_query,
                'response': ai_response,
                'query_type': query_type,
                'context_quality': context_quality,
                'sources_count': len(sources),
                'web_search_used': web_search_used,
                'similarity_threshold': SIMILARITY_THRESHOLD,
                'selected_drawing': final_selected_drawing,
                'search_results_count': len(search_results)
            })
            
            return {
                'response': ai_response,
                'sources': sources,
                'query_type': query_type,
                'context_quality': context_quality,
                'web_search_used': web_search_used,
                'similarity_threshold': SIMILARITY_THRESHOLD,
                'high_quality_sources': len(high_quality_chunks),
                'low_quality_sources': len(low_quality_chunks),
                'selected_drawing': final_selected_drawing,
                'drawing_context_used': bool(drawing_context),
                'search_results': search_results,
                'auto_selected_drawing': auto_selected_drawing
            }
            
        except Exception as e:
            logger.error(f"ì‘ë‹µ ìƒì„± ì‹¤íŒ¨: {e}")
            return {
                'response': f"ì£„ì†¡í•©ë‹ˆë‹¤. ì‘ë‹µ ìƒì„± ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {str(e)}",
                'sources': [],
                'query_type': 'error',
                'context_quality': 'none',
                'web_search_used': False,
                'similarity_threshold': 0.4,
                'selected_drawing': selected_drawing,
                'search_results': []
            }

    def _build_source_summary(self, sources: List[Dict], threshold: float) -> str:
        """ì†ŒìŠ¤ ìš”ì•½ ì •ë³´ ìƒì„±"""
        if not sources:
            return ""
        
        summary_parts = []
        summary_parts.append("---")
        summary_parts.append("**ğŸ“‹ ì •ë³´ ì¶œì²˜:**")
        
        rag_sources = [s for s in sources if s['type'] == 'rag']
        web_sources = [s for s in sources if s['type'] == 'web']
        
        if rag_sources:
            high_quality = [s for s in rag_sources if s.get('quality') == 'high']
            low_quality = [s for s in rag_sources if s.get('quality') == 'low']
            
            if high_quality:
                summary_parts.append(f"ğŸ“– **RAG ë°ì´í„°ë² ì´ìŠ¤** (ê³ í’ˆì§ˆ, ìœ ì‚¬ë„ â‰¥ {threshold}): {len(high_quality)}ê°œ")
                for source in high_quality:
                    summary_parts.append(f"  â€¢ í˜ì´ì§€ {source['page']}, ìœ ì‚¬ë„: {source['score']:.3f}")
            
            if low_quality:
                summary_parts.append(f"ğŸ“– **RAG ë°ì´í„°ë² ì´ìŠ¤** (ì°¸ê³ ìš©, ìœ ì‚¬ë„ < {threshold}): {len(low_quality)}ê°œ")
                for source in low_quality:
                    summary_parts.append(f"  â€¢ í˜ì´ì§€ {source['page']}, ìœ ì‚¬ë„: {source['score']:.3f}")
        
        if web_sources:
            summary_parts.append(f"ğŸŒ **ì¸í„°ë„· ê²€ìƒ‰**: {len(web_sources)}ê°œ")
            summary_parts.append("  â€¢ GPT-4 ê¸°ë°˜ ìµœì‹  ì •ë³´ ê²€ìƒ‰")
        
        return "\n".join(summary_parts)

    def get_conversation_summary(self) -> Dict:
        """ëŒ€í™” ìš”ì•½ í†µê³„"""
        if not self.conversation_history:
            return {}
        
        total_queries = len(self.conversation_history)
        query_types = {}
        context_qualities = {}
        
        for conv in self.conversation_history:
            query_type = conv.get('query_type', 'unknown')
            context_quality = conv.get('context_quality', 'unknown')
            
            query_types[query_type] = query_types.get(query_type, 0) + 1
            context_qualities[context_quality] = context_qualities.get(context_quality, 0) + 1
        
        return {
            'total_queries': total_queries,
            'query_types': query_types,
            'context_qualities': context_qualities,
            'average_sources_per_query': sum(conv.get('sources_count', 0) for conv in self.conversation_history) / total_queries
        }

    def clear_conversation_history(self):
        """ëŒ€í™” ê¸°ë¡ ì‚­ì œ"""
        self.conversation_history = []
        logger.info("ëŒ€í™” ê¸°ë¡ì´ ì‚­ì œë˜ì—ˆìŠµë‹ˆë‹¤.")

    def export_conversation_history(self) -> str:
        """ëŒ€í™” ê¸°ë¡ ë‚´ë³´ë‚´ê¸°"""
        if not self.conversation_history:
            return "ëŒ€í™” ê¸°ë¡ì´ ì—†ìŠµë‹ˆë‹¤."
        
        export_text = "P&ID ì „ë¬¸ê°€ ì±—ë´‡ ëŒ€í™” ê¸°ë¡\n"
        export_text += "=" * 50 + "\n\n"
        
        for i, conv in enumerate(self.conversation_history, 1):
            export_text += f"ëŒ€í™” {i}\n"
            export_text += f"ì‹œê°„: {conv['timestamp'].strftime('%Y-%m-%d %H:%M:%S')}\n"
            export_text += f"ì§ˆë¬¸: {conv['user_query']}\n"
            export_text += f"ë‹µë³€: {conv['response']}\n"
            export_text += f"ì¿¼ë¦¬ ìœ í˜•: {conv['query_type']}\n"
            export_text += f"ì»¨í…ìŠ¤íŠ¸ í’ˆì§ˆ: {conv['context_quality']}\n"
            export_text += "-" * 30 + "\n\n"
        
        return export_text

    def create_internal_data_prompt(self, user_question, rag_context):
        """ë‚´ë¶€ ë°ì´í„° ì „ìš© í”„ë¡¬í”„íŠ¸ ìƒì„± - ì›¹ ê²€ìƒ‰ ì—†ì´ RAGë§Œ ì‚¬ìš©"""
        
        internal_expert_persona = """ë‹¹ì‹ ì€ 20ë…„ ê²½ë ¥ì˜ P&ID ë° ê³µì • ì œì–´ ì‹œìŠ¤í…œ ì „ë¬¸ê°€ì…ë‹ˆë‹¤.

**ì „ë¬¸ ë¶„ì•¼:**
- P&ID ë„ë©´ í•´ì„ ë° ë¶„ì„
- ê³µì • ì‹œìŠ¤í…œ ì„¤ê³„ ë° ìš´ì „
- ê³„ì¸¡ ë° ì œì–´ ì‹œìŠ¤í…œ ë¶„ì„
- ê³µì • ì•ˆì „ ê´€ë¦¬
- ì„¤ë¹„ ë° ì¥ì¹˜ ìš´ì „

**ì¤‘ìš” ì›ì¹™:**
âš ï¸ **ê¸°ë°€ì„± ì¤€ìˆ˜**: ì œê³µëœ ë‚´ë¶€ ë¬¸ì„œë§Œì„ ê¸°ë°˜ìœ¼ë¡œ ë‹µë³€í•˜ë©°, ì™¸ë¶€ ì •ë³´ëŠ” ì ˆëŒ€ ì‚¬ìš©í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤.
ğŸ“‹ **ì •í™•ì„± ìš°ì„ **: ë¬¸ì„œì— ëª…ì‹œë˜ì§€ ì•Šì€ ë‚´ìš©ì€ ì¶”ì¸¡í•˜ì§€ ì•Šìœ¼ë©°, ë¶ˆí™•ì‹¤í•œ ë¶€ë¶„ì€ ëª…í™•íˆ í‘œì‹œí•©ë‹ˆë‹¤.
ğŸ” **ìƒì„¸ ë¶„ì„**: ì œê³µëœ ë¬¸ì„œì˜ ë‚´ìš©ì„ ì²´ê³„ì ì´ê³  ìƒì„¸í•˜ê²Œ ë¶„ì„í•©ë‹ˆë‹¤.

**ë‹µë³€ êµ¬ì¡°:**
1. **í•µì‹¬ ìš”ì•½** (ë¬¸ì„œ ê¸°ë°˜ ì£¼ìš” ë‚´ìš©)
2. **ìƒì„¸ ë¶„ì„** (ê¸°ìˆ ì  ì„¸ë¶€ì‚¬í•­)
3. **ìš´ì „ ê´€ë ¨ ì‚¬í•­** (ì‹¤ë¬´ì  ê³ ë ¤ì‚¬í•­)
4. **ì£¼ì˜ì‚¬í•­** (ì•ˆì „ ë° ì œì•½ ì¡°ê±´)
5. **ë¬¸ì„œ ê¸°ë°˜ ì œí•œì‚¬í•­** (í™•ì¸ì´ í•„ìš”í•œ ë¶€ë¶„)

**ë‹µë³€ ìŠ¤íƒ€ì¼:**
- ë¬¸ì„œì— ê·¼ê±°í•œ ì •í™•í•œ ì •ë³´ë§Œ ì œê³µ
- "ë¬¸ì„œì— ë”°ë¥´ë©´...", "ì œê³µëœ ìë£Œì—ì„œ..." ë“±ì˜ í‘œí˜„ ì‚¬ìš©
- ë¶ˆí™•ì‹¤í•œ ë‚´ìš©ì€ "ë¬¸ì„œì—ì„œ í™•ì¸ë˜ì§€ ì•ŠìŒ" ëª…ì‹œ"""

        # ë‚´ë¶€ ë°ì´í„° ì „ìš© ì‹œìŠ¤í…œ í”„ë¡¬í”„íŠ¸
        system_prompt = f"""{internal_expert_persona}

**ì œê³µëœ ë‚´ë¶€ ë¬¸ì„œ:**
{rag_context if rag_context else "ê´€ë ¨ ë‚´ë¶€ ë¬¸ì„œê°€ ì—†ìŠµë‹ˆë‹¤."}

**ì¤‘ìš” ì§€ì¹¨:**
1. ì˜¤ì§ ìœ„ì— ì œê³µëœ ë‚´ë¶€ ë¬¸ì„œë§Œì„ ê¸°ë°˜ìœ¼ë¡œ ë‹µë³€í•˜ì„¸ìš”
2. ì™¸ë¶€ ì§€ì‹ì´ë‚˜ ì¼ë°˜ì ì¸ ì •ë³´ëŠ” ì‚¬ìš©í•˜ì§€ ë§ˆì„¸ìš”
3. ë¬¸ì„œì— ì—†ëŠ” ë‚´ìš©ì€ "ì œê³µëœ ë¬¸ì„œì—ì„œ í™•ì¸í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤"ë¼ê³  ëª…ì‹œí•˜ì„¸ìš”
4. ëª¨ë“  ë‹µë³€ì€ ë¬¸ì„œì˜ êµ¬ì²´ì  ë‚´ìš©ì„ ì¸ìš©í•˜ì—¬ ê·¼ê±°ë¥¼ ì œì‹œí•˜ì„¸ìš”

ìœ„ ì§€ì¹¨ì„ ì—„ê²©íˆ ì¤€ìˆ˜í•˜ì—¬ ì‚¬ìš©ìì˜ ì§ˆë¬¸ì— ë‹µë³€í•´ì£¼ì„¸ìš”."""

        return system_prompt

    def get_all_drawing_names(self) -> List[str]:
        """
        ë°ì´í„°ë² ì´ìŠ¤ì—ì„œ ëª¨ë“  ë„ë©´ íŒŒì¼ëª…ì„ ì¡°íšŒ
        
        Returns:
            ë„ë©´ íŒŒì¼ëª… ë¦¬ìŠ¤íŠ¸ (ì¤‘ë³µ ì œê±°)
        """
        try:
            conn = get_db_connection()
            if not conn:
                logger.error("ë°ì´í„°ë² ì´ìŠ¤ ì—°ê²° ì‹¤íŒ¨")
                return []
            
            cursor = conn.cursor()
            
            query = """
            SELECT DISTINCT d_name
            FROM domyun 
            ORDER BY d_name
            """
            
            cursor.execute(query)
            results = cursor.fetchall()
            
            cursor.close()
            conn.close()
            
            # íŒŒì¼ëª…ë§Œ ì¶”ì¶œ
            drawing_names = [result[0] for result in results if result[0]]
            
            logger.info(f"ë°ì´í„°ë² ì´ìŠ¤ì—ì„œ {len(drawing_names)}ê°œì˜ ë„ë©´ íŒŒì¼ëª… ì¡°íšŒë¨")
            return drawing_names
                
        except Exception as e:
            logger.error(f"ë„ë©´ íŒŒì¼ëª… ì¡°íšŒ ì‹¤íŒ¨: {e}")
            return []

    def get_drawing_versions_info(self, d_name: str) -> List[Dict]:
        """
        íŠ¹ì • ë„ë©´ì˜ ëª¨ë“  ë²„ì „ ì •ë³´ë¥¼ ì¡°íšŒ (ë©”íƒ€ë°ì´í„°ë§Œ)
        
        Args:
            d_name: ë„ë©´ íŒŒì¼ëª…
        
        Returns:
            ë²„ì „ ì •ë³´ ë¦¬ìŠ¤íŠ¸ (ìµœì‹ ìˆœ)
        """
        try:
            conn = get_db_connection()
            if not conn:
                logger.error("ë°ì´í„°ë² ì´ìŠ¤ ì—°ê²° ì‹¤íŒ¨")
                return []
            
            cursor = conn.cursor()
            
            query = """
            SELECT d_id, "user", create_date
            FROM domyun 
            WHERE d_name = %s 
            ORDER BY create_date DESC
            """
            
            cursor.execute(query, (d_name,))
            results = cursor.fetchall()
            
            cursor.close()
            conn.close()
            
            versions = []
            for i, result in enumerate(results):
                d_id, user, create_date = result
                versions.append({
                    'd_id': d_id,
                    'user': user,
                    'create_date': create_date,
                    'version_label': f"ë²„ì „ {i+1}" if i > 0 else "ìµœì‹ ",
                    'is_latest': i == 0
                })
            
            return versions
                
        except Exception as e:
            logger.error(f"ë„ë©´ ë²„ì „ ì •ë³´ ì¡°íšŒ ì‹¤íŒ¨: {e}")
            return []

    def generate_drawing_summary(self, d_name: str, version: str = "latest") -> Dict:
        """
        íŠ¹ì • ë„ë©´ì˜ ìš”ì•½ ì •ë³´ë¥¼ ìƒì„±
        
        Args:
            d_name: ë„ë©´ íŒŒì¼ëª…
            version: "latest" (ìµœì‹ ) ë˜ëŠ” "previous" (ì´ì „) ë˜ëŠ” d_id
        
        Returns:
            ìš”ì•½ ì •ë³´ê°€ í¬í•¨ëœ ì‘ë‹µ ë”•ì…”ë„ˆë¦¬
        """
        try:
            # ë„ë©´ ë°ì´í„° ì¡°íšŒ
            if version.isdigit():
                # d_idë¡œ ì§ì ‘ ì¡°íšŒ
                drawing_data = self.get_drawing_data_by_id(int(version))
            else:
                drawing_data = self.get_drawing_data_from_db(d_name, version)
            
            if not drawing_data:
                return {
                    'response': f"âŒ '{d_name}' ({version}) ë„ë©´ì„ ë°ì´í„°ë² ì´ìŠ¤ì—ì„œ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.",
                    'sources': [],
                    'query_type': 'drawing_summary',
                    'context_quality': 'none',
                    'web_search_used': False,
                    'drawing_data': None
                }
            
            # ë„ë©´ì—ì„œ í…ìŠ¤íŠ¸ ì¶”ì¶œ
            extracted_text = self.extract_text_from_drawing_data(drawing_data)
            
            # ìš”ì•½ ìƒì„±ì„ ìœ„í•œ í”„ë¡¬í”„íŠ¸
            summary_prompt = f"""ë‹¹ì‹ ì€ P&ID ë„ë©´ ë¶„ì„ ì „ë¬¸ê°€ì…ë‹ˆë‹¤. ë‹¤ìŒ ë„ë©´ ì •ë³´ë¥¼ ë°”íƒ•ìœ¼ë¡œ ì „ë¬¸ì ì´ê³  êµ¬ì¡°í™”ëœ ìš”ì•½ì„ ì‘ì„±í•´ì£¼ì„¸ìš”.

**ë„ë©´ ì •ë³´:**
- íŒŒì¼ëª…: {drawing_data.get('d_name')}
- ë“±ë¡ì¼: {drawing_data.get('create_date')}
- ë“±ë¡ì: {drawing_data.get('user')}

**ì¶”ì¶œëœ í…ìŠ¤íŠ¸:**
{extracted_text if extracted_text else 'í…ìŠ¤íŠ¸ ì •ë³´ ì—†ìŒ'}

**ìš”ì•½ êµ¬ì¡°:**
1. **ë„ë©´ ê°œìš”** (ë„ë©´ì˜ ëª©ì ê³¼ ì£¼ìš” ê¸°ëŠ¥)
2. **ì£¼ìš” êµ¬ì„± ìš”ì†Œ** (ê³„ì¸¡ê¸°ê¸°, ë°¸ë¸Œ, íŒí”„ ë“±)
3. **ì œì–´ ì‹œìŠ¤í…œ** (ì œì–´ ë£¨í”„ ë° ì•ˆì „ì¥ì¹˜)
4. **ìš´ì „ íŠ¹ì„±** (ì£¼ìš” ìš´ì „ ì¡°ê±´ ë° ì ˆì°¨)
5. **ì•ˆì „ ê³ ë ¤ì‚¬í•­** (ì•ˆì „ì¥ì¹˜ ë° ë¹„ìƒëŒ€ì‘)

ê° ì„¹ì…˜ì„ ëª…í™•íˆ êµ¬ë¶„í•˜ì—¬ ì‘ì„±í•˜ê³ , ê°€ëŠ¥í•œ í•œ êµ¬ì²´ì ì¸ íƒœê·¸ ë²ˆí˜¸ë‚˜ ì„¤ë¹„ëª…ì„ í¬í•¨í•´ì£¼ì„¸ìš”.
ì¶”ì¶œëœ í…ìŠ¤íŠ¸ê°€ ë¶€ì¡±í•˜ë‹¤ë©´ ì¼ë°˜ì ì¸ P&ID ë¶„ì„ ì›ì¹™ì— ë”°ë¼ ë³´ì™„ ì„¤ëª…ì„ ì œê³µí•˜ë˜, 
"ì¶”ì¶œëœ ì •ë³´ ê¸°ë°˜" vs "ì¼ë°˜ì  ì„¤ëª…" ì„ ëª…í™•íˆ êµ¬ë¶„í•´ì£¼ì„¸ìš”."""

            # OpenAI API í˜¸ì¶œ
            if not self.client:
                return {
                    'response': "OpenAI API í‚¤ê°€ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.",
                    'sources': [],
                    'query_type': 'drawing_summary',
                    'context_quality': 'none',
                    'web_search_used': False,
                    'drawing_data': drawing_data
                }
            
            try:
                response = self.client.chat.completions.create(
                    model="gpt-4o-mini",
                    messages=[
                        {"role": "system", "content": "ë‹¹ì‹ ì€ 20ë…„ ê²½ë ¥ì˜ P&ID ì „ë¬¸ê°€ì…ë‹ˆë‹¤. ì •í™•í•˜ê³  ì‹¤ìš©ì ì¸ ë„ë©´ ë¶„ì„ì„ ì œê³µí•©ë‹ˆë‹¤."},
                        {"role": "user", "content": summary_prompt}
                    ],
                    temperature=0.2,
                    max_tokens=2000
                )
                
                summary_response = response.choices[0].message.content
                
                # ë„ë©´ ì •ë³´ ì¶”ê°€
                final_response = f"""ğŸ“‹ **ë„ë©´ ìš”ì•½ ë¶„ì„**

**ğŸ“„ ë„ë©´ ì •ë³´:**
- **íŒŒì¼ëª…:** {drawing_data.get('d_name')}
- **ë“±ë¡ì¼:** {drawing_data.get('create_date')}
- **ë“±ë¡ì:** {drawing_data.get('user')}
- **ë²„ì „:** {version}

---

{summary_response}

---

**ğŸ“Š ì¶”ì¶œ í†µê³„:**
- **í…ìŠ¤íŠ¸ ê¸¸ì´:** {len(extracted_text)} ë¬¸ì
- **JSON ë°ì´í„°:** {'ìˆìŒ' if drawing_data.get('json_data') else 'ì—†ìŒ'}
"""
                
                # ì†ŒìŠ¤ ì •ë³´ êµ¬ì„±
                sources = [{
                    'type': 'database',
                    'icon': 'ğŸ—„ï¸',
                    'source': f'ë„ë©´ ë°ì´í„°ë² ì´ìŠ¤ - {d_name}',
                    'score': None,
                    'page': None,
                    'content_preview': f"ë“±ë¡ì¼: {drawing_data.get('create_date')}, ë“±ë¡ì: {drawing_data.get('user')}",
                    'quality': 'high'
                }]
                
                return {
                    'response': final_response,
                    'sources': sources,
                    'query_type': 'drawing_summary',
                    'context_quality': 'high',
                    'web_search_used': False,
                    'drawing_data': drawing_data,
                    'extracted_text_length': len(extracted_text)
                }
                
            except Exception as e:
                logger.error(f"OpenAI API í˜¸ì¶œ ì‹¤íŒ¨: {e}")
                return {
                    'response': f"ìš”ì•½ ìƒì„± ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {str(e)}",
                    'sources': [],
                    'query_type': 'drawing_summary',
                    'context_quality': 'none',
                    'web_search_used': False,
                    'drawing_data': drawing_data
                }
                
        except Exception as e:
            logger.error(f"ë„ë©´ ìš”ì•½ ìƒì„± ì‹¤íŒ¨: {e}")
            return {
                'response': f"ë„ë©´ ìš”ì•½ ìƒì„± ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {str(e)}",
                'sources': [],
                'query_type': 'drawing_summary',
                'context_quality': 'none',
                'web_search_used': False,
                'drawing_data': None
            }

    def get_drawing_data_by_id(self, d_id: int) -> Optional[Dict]:
        """
        d_idë¡œ íŠ¹ì • ë„ë©´ ë°ì´í„°ë¥¼ ì¡°íšŒ
        
        Args:
            d_id: ë„ë©´ ID
        
        Returns:
            ë„ë©´ ë°ì´í„° ë˜ëŠ” None
        """
        try:
            conn = get_db_connection()
            if not conn:
                logger.error("ë°ì´í„°ë² ì´ìŠ¤ ì—°ê²° ì‹¤íŒ¨")
                return None
            
            cursor = conn.cursor()
            
            query = """
            SELECT d_id, d_name, "user", create_date, json_data, image_path
            FROM domyun 
            WHERE d_id = %s
            """
            
            cursor.execute(query, (d_id,))
            result = cursor.fetchone()
            
            cursor.close()
            conn.close()
            
            if result:
                d_id, d_name, user, create_date, json_data, image_path = result
                return {
                    'd_id': d_id,
                    'd_name': d_name,
                    'user': user,
                    'create_date': create_date,
                    'json_data': json_data,
                    'image_path': image_path
                }
            else:
                logger.warning(f"ë„ë©´ ID '{d_id}'ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤")
                return None
                
        except Exception as e:
            logger.error(f"ë°ì´í„°ë² ì´ìŠ¤ ì¡°íšŒ ì‹¤íŒ¨: {e}")
            return None

    def search_drawings_by_name(self, search_term: str) -> List[Dict]:
        """
        ë„ë©´ ì´ë¦„ìœ¼ë¡œ LIKE ê²€ìƒ‰ì„ ìˆ˜í–‰
        
        Args:
            search_term: ê²€ìƒ‰í•  ë„ë©´ ì´ë¦„ (ë¶€ë¶„ ê²€ìƒ‰ ê°€ëŠ¥)
        
        Returns:
            ê²€ìƒ‰ëœ ë„ë©´ ì •ë³´ ë¦¬ìŠ¤íŠ¸ (ìµœì‹ ìˆœ)
        """
        try:
            conn = get_db_connection()
            if not conn:
                logger.error("ë°ì´í„°ë² ì´ìŠ¤ ì—°ê²° ì‹¤íŒ¨")
                return []
            
            cursor = conn.cursor()
            
            # LIKE ê²€ìƒ‰ ì¿¼ë¦¬ (ëŒ€ì†Œë¬¸ì êµ¬ë¶„ ì—†ì´)
            query = """
            SELECT DISTINCT d_name,
                   COUNT(*) as version_count,
                   MAX(create_date) as latest_date,
                   STRING_AGG(DISTINCT "user", ', ') as users
            FROM domyun 
            WHERE LOWER(d_name) LIKE LOWER(%s)
            GROUP BY d_name
            ORDER BY latest_date DESC
            """
            
            search_pattern = f"%{search_term}%"
            cursor.execute(query, (search_pattern,))
            results = cursor.fetchall()
            
            cursor.close()
            conn.close()
            
            # ê²°ê³¼ë¥¼ ë”•ì…”ë„ˆë¦¬ ë¦¬ìŠ¤íŠ¸ë¡œ ë³€í™˜
            drawings = []
            for d_name, version_count, latest_date, users in results:
                drawings.append({
                    'd_name': d_name,
                    'version_count': version_count,
                    'latest_date': latest_date,
                    'users': users
                })
            
            logger.info(f"ë„ë©´ ê²€ìƒ‰ '{search_term}': {len(drawings)}ê°œ ê²°ê³¼")
            return drawings
                
        except Exception as e:
            logger.error(f"ë„ë©´ ê²€ìƒ‰ ì‹¤íŒ¨: {e}")
            return []

    def extract_drawing_names_from_query(self, query: str) -> List[str]:
        """
        ì‚¬ìš©ì ì§ˆë¬¸ì—ì„œ ë„ë©´ ì´ë¦„ í›„ë³´ë¥¼ ì¶”ì¶œ
        
        Args:
            query: ì‚¬ìš©ì ì§ˆë¬¸
        
        Returns:
            ì¶”ì¶œëœ ë„ë©´ ì´ë¦„ í›„ë³´ ë¦¬ìŠ¤íŠ¸
        """
        import re
        
        # ë„ë©´ ì´ë¦„ íŒ¨í„´ë“¤
        drawing_patterns = [
            r'([a-zA-Z0-9_\-]+\.(?:pdf|png|jpg|jpeg))',  # í™•ì¥ì í¬í•¨ íŒŒì¼ëª…
            r'([a-zA-Z0-9_\-]{3,})',  # 3ìë¦¬ ì´ìƒ ì˜ìˆ«ì+ì–¸ë”ìŠ¤ì½”ì–´
            r'([ê°€-í£]{2,})',  # 2ìë¦¬ ì´ìƒ í•œê¸€
        ]
        
        # ë„ë©´ ê´€ë ¨ í‚¤ì›Œë“œê°€ í¬í•¨ëœ ê²½ìš°ë§Œ ì²˜ë¦¬
        drawing_keywords = ['ë„ë©´', 'íŒŒì¼', 'ê·¸ë¦¼', 'pdf', 'stream', 'does', 'ai']
        has_drawing_keyword = any(keyword.lower() in query.lower() for keyword in drawing_keywords)
        
        if not has_drawing_keyword:
            return []
        
        candidates = set()
        
        # ê° íŒ¨í„´ìœ¼ë¡œ í›„ë³´ ì¶”ì¶œ
        for pattern in drawing_patterns:
            matches = re.findall(pattern, query, re.IGNORECASE)
            candidates.update(matches)
        
        # ë”°ì˜´í‘œë‚˜ ê´„í˜¸ë¡œ ê°ì‹¼ í…ìŠ¤íŠ¸ ì¶”ì¶œ
        quoted_patterns = [
            r'"([^"]+)"',  # í°ë”°ì˜´í‘œ
            r"'([^']+)'",  # ì‘ì€ë”°ì˜´í‘œ
            r'\(([^)]+)\)',  # ê´„í˜¸
        ]
        
        for pattern in quoted_patterns:
            matches = re.findall(pattern, query)
            candidates.update(matches)
        
        # ë„ˆë¬´ ì§§ê±°ë‚˜ ê¸´ í›„ë³´ í•„í„°ë§
        filtered_candidates = []
        for candidate in candidates:
            candidate = candidate.strip()
            if 2 <= len(candidate) <= 50 and candidate not in ['ë„ë©´', 'íŒŒì¼', 'ê·¸ë¦¼']:
                filtered_candidates.append(candidate)
        
        return list(filtered_candidates)

    def create_drawing_search_prompt(self, user_question, search_results, rag_context):
        """ë„ë©´ ê²€ìƒ‰ ì „ìš© í”„ë¡¬í”„íŠ¸ ìƒì„±"""
        
        drawing_search_persona = """ë‹¹ì‹ ì€ 20ë…„ ê²½ë ¥ì˜ P&ID ë„ë©´ ê´€ë¦¬ ì „ë¬¸ê°€ì…ë‹ˆë‹¤.

**ì „ë¬¸ ë¶„ì•¼:**
- P&ID ë„ë©´ ë°ì´í„°ë² ì´ìŠ¤ ê²€ìƒ‰ ë° ê´€ë¦¬
- ë„ë©´ ì •ë³´ ë¶„ì„ ë° ì¶”ì²œ
- ì‚¬ìš©ì ìš”êµ¬ì‚¬í•­ì— ë§ëŠ” ë„ë©´ ì‹ë³„
- ë„ë©´ ë²„ì „ ê´€ë¦¬ ë° ì´ë ¥ ì¶”ì 

**ê²€ìƒ‰ ë¶„ì„ ì ‘ê·¼ë²•:**
1. **ê²€ìƒ‰ ê²°ê³¼ í‰ê°€**: ì°¾ì€ ë„ë©´ë“¤ì˜ ê´€ë ¨ì„± ë° ì í•©ì„± ë¶„ì„
2. **ë„ë©´ ì •ë³´ ì œê³µ**: ê° ë„ë©´ì˜ íŠ¹ì§•ê³¼ ë²„ì „ ì •ë³´ ì„¤ëª…
3. **ì¶”ì²œ ë° ì•ˆë‚´**: ì‚¬ìš©ì ì§ˆë¬¸ì— ê°€ì¥ ì í•©í•œ ë„ë©´ ì¶”ì²œ
4. **ì¶”ê°€ ì •ë³´**: í•„ìš”í•œ ê²½ìš° ê´€ë ¨ ë„ë©´ì´ë‚˜ ì¶”ê°€ ê²€ìƒ‰ ì œì•ˆ

**ë‹µë³€ êµ¬ì¡°:**
1. **ê²€ìƒ‰ ê²°ê³¼ ìš”ì•½** (ì°¾ì€ ë„ë©´ ìˆ˜ì™€ ì£¼ìš” ê²°ê³¼)
2. **ë„ë©´ë³„ ìƒì„¸ ì •ë³´** (ì´ë¦„, ë²„ì „, ë“±ë¡ì, ë‚ ì§œ)
3. **ì¶”ì²œ ë„ë©´** (ì§ˆë¬¸ì— ê°€ì¥ ì í•©í•œ ë„ë©´)
4. **ì¶”ê°€ ì•ˆë‚´** (ê´€ë ¨ ì •ë³´ë‚˜ ë‹¤ìŒ ë‹¨ê³„ ì œì•ˆ)"""

        # ê²€ìƒ‰ ê²°ê³¼ ì •ë³´ êµ¬ì„±
        search_info = ""
        if search_results:
            search_info = f"**ê²€ìƒ‰ ê²°ê³¼ ({len(search_results)}ê°œ ë„ë©´ ë°œê²¬):**\n\n"
            for i, result in enumerate(search_results, 1):
                search_info += f"{i}. **{result['d_name']}**\n"
                search_info += f"   - ë²„ì „ ìˆ˜: {result['version_count']}ê°œ\n"
                search_info += f"   - ìµœì¢… ìˆ˜ì •: {result['latest_date']}\n"
                search_info += f"   - ë“±ë¡ì: {result['users']}\n\n"
        else:
            search_info = "**ê²€ìƒ‰ ê²°ê³¼:** ì¡°ê±´ì— ë§ëŠ” ë„ë©´ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.\n\n"

        # ì „ì²´ í”„ë¡¬í”„íŠ¸ êµ¬ì„±
        system_prompt = f"""{drawing_search_persona}

**ì‚¬ìš©ì ì§ˆë¬¸:**
{user_question}

**ë„ë©´ ê²€ìƒ‰ ê²°ê³¼:**
{search_info}

**ì°¸ê³  ë¬¸ì„œ ì •ë³´:**
{rag_context}

ì‚¬ìš©ìê°€ ë„ë©´ì— ëŒ€í•´ ì§ˆë¬¸í–ˆìŠµë‹ˆë‹¤. ë„ë©´ ê²€ìƒ‰ ì „ë¬¸ê°€ë¡œì„œ ë‹¤ìŒ ì‚¬í•­ì„ ì¤‘ì ì ìœ¼ë¡œ ë¶„ì„í•´ì£¼ì„¸ìš”:

- ê²€ìƒ‰ëœ ë„ë©´ë“¤ì˜ íŠ¹ì§•ê³¼ ì°¨ì´ì 
- ì‚¬ìš©ì ì§ˆë¬¸ì— ê°€ì¥ ì í•©í•œ ë„ë©´ ì¶”ì²œ
- ê° ë„ë©´ì˜ ë²„ì „ ë° ì´ë ¥ ì •ë³´
- í•„ìš”í•œ ê²½ìš° ì¶”ê°€ ê²€ìƒ‰ì´ë‚˜ ê´€ë ¨ ë„ë©´ ì œì•ˆ

ê²€ìƒ‰ ê²°ê³¼ë¥¼ ë°”íƒ•ìœ¼ë¡œ ì „ë¬¸ì ì´ê³  ì‹¤ìš©ì ì¸ ë„ë©´ ì •ë³´ë¥¼ ì œê³µí•´ì£¼ì„¸ìš”."""

        return system_prompt

    def get_drawing_data_by_id(self, d_id: int) -> Optional[Dict]:
        """
        d_idë¡œ íŠ¹ì • ë„ë©´ ë°ì´í„°ë¥¼ ì¡°íšŒ
        
        Args:
            d_id: ë„ë©´ ID
        
        Returns:
            ë„ë©´ ë°ì´í„° ë˜ëŠ” None
        """
        try:
            conn = get_db_connection()
            if not conn:
                logger.error("ë°ì´í„°ë² ì´ìŠ¤ ì—°ê²° ì‹¤íŒ¨")
                return None
            
            cursor = conn.cursor()
            
            query = """
            SELECT d_id, d_name, "user", create_date, json_data, image_path
            FROM domyun 
            WHERE d_id = %s
            """
            
            cursor.execute(query, (d_id,))
            result = cursor.fetchone()
            
            cursor.close()
            conn.close()
            
            if result:
                d_id, d_name, user, create_date, json_data, image_path = result
                return {
                    'd_id': d_id,
                    'd_name': d_name,
                    'user': user,
                    'create_date': create_date,
                    'json_data': json_data,
                    'image_path': image_path
                }
            else:
                logger.warning(f"ë„ë©´ ID '{d_id}'ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤")
                return None
                
        except Exception as e:
            logger.error(f"ë°ì´í„°ë² ì´ìŠ¤ ì¡°íšŒ ì‹¤íŒ¨: {e}")
            return None

    def search_drawings_by_name(self, search_term: str) -> List[Dict]:
        """
        ë„ë©´ ì´ë¦„ìœ¼ë¡œ LIKE ê²€ìƒ‰ì„ ìˆ˜í–‰
        
        Args:
            search_term: ê²€ìƒ‰í•  ë„ë©´ ì´ë¦„ (ë¶€ë¶„ ê²€ìƒ‰ ê°€ëŠ¥)
        
        Returns:
            ê²€ìƒ‰ëœ ë„ë©´ ì •ë³´ ë¦¬ìŠ¤íŠ¸ (ìµœì‹ ìˆœ)
        """
        try:
            conn = get_db_connection()
            if not conn:
                logger.error("ë°ì´í„°ë² ì´ìŠ¤ ì—°ê²° ì‹¤íŒ¨")
                return []
            
            cursor = conn.cursor()
            
            # LIKE ê²€ìƒ‰ ì¿¼ë¦¬ (ëŒ€ì†Œë¬¸ì êµ¬ë¶„ ì—†ì´)
            query = """
            SELECT DISTINCT d_name,
                   COUNT(*) as version_count,
                   MAX(create_date) as latest_date,
                   STRING_AGG(DISTINCT "user", ', ') as users
            FROM domyun 
            WHERE LOWER(d_name) LIKE LOWER(%s)
            GROUP BY d_name
            ORDER BY latest_date DESC
            """
            
            search_pattern = f"%{search_term}%"
            cursor.execute(query, (search_pattern,))
            results = cursor.fetchall()
            
            cursor.close()
            conn.close()
            
            # ê²°ê³¼ë¥¼ ë”•ì…”ë„ˆë¦¬ ë¦¬ìŠ¤íŠ¸ë¡œ ë³€í™˜
            drawings = []
            for d_name, version_count, latest_date, users in results:
                drawings.append({
                    'd_name': d_name,
                    'version_count': version_count,
                    'latest_date': latest_date,
                    'users': users
                })
            
            logger.info(f"ë„ë©´ ê²€ìƒ‰ '{search_term}': {len(drawings)}ê°œ ê²°ê³¼")
            return drawings
                
        except Exception as e:
            logger.error(f"ë„ë©´ ê²€ìƒ‰ ì‹¤íŒ¨: {e}")
            return []

    def visualize_drawing_analysis(self, d_name: str, version: str = "latest") -> Optional[Dict]:
        """
        ë„ë©´ ì‹œê°í™” ë¶„ì„ - OCRê³¼ Detection ê²°ê³¼ë¥¼ ì´ë¯¸ì§€ì— ê·¸ë ¤ì„œ ë°˜í™˜
        
        Args:
            d_name: ë„ë©´ íŒŒì¼ëª…
            version: "latest" (ìµœì‹ ) ë˜ëŠ” "previous" (ì´ì „) ë˜ëŠ” d_id
        
        Returns:
            ì‹œê°í™”ëœ ì´ë¯¸ì§€ ì •ë³´ì™€ ë¶„ì„ ê²°ê³¼
        """
        try:
            # ë„ë©´ ë°ì´í„° ì¡°íšŒ
            if version.isdigit():
                drawing_data = self.get_drawing_data_by_id(int(version))
            else:
                drawing_data = self.get_drawing_data_from_db(d_name, version)
            
            if not drawing_data:
                logger.error(f"ë„ë©´ '{d_name}' ({version})ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤")
                return None
            
            # ì´ë¯¸ì§€ ê²½ë¡œ í™•ì¸
            image_path = drawing_data.get('image_path')
            if not image_path or not os.path.exists(image_path):
                logger.error(f"ì´ë¯¸ì§€ íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {image_path}")
                return None
            
            # JSON ë°ì´í„° í™•ì¸
            json_data = drawing_data.get('json_data')
            if not json_data:
                logger.error("JSON ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤")
                return None
            
            # ì´ë¯¸ì§€ ë¡œë“œ
            original_image = Image.open(image_path)
            
            # JSONì—ì„œ ì˜ˆìƒ í¬ê¸° ê°€ì ¸ì˜¤ê¸°
            expected_width = json_data.get('width', original_image.width)
            expected_height = json_data.get('height', original_image.height)
            
            # ì´ë¯¸ì§€ í¬ê¸° ì¡°ì •
            if original_image.size != (expected_width, expected_height):
                logger.info(f"ì´ë¯¸ì§€ í¬ê¸° ì¡°ì •: {original_image.size} -> ({expected_width}, {expected_height})")
                image = original_image.resize((expected_width, expected_height), Image.Resampling.LANCZOS)
            else:
                image = original_image.copy()
            
            # ê·¸ë¦¬ê¸° ê°ì²´ ìƒì„±
            draw = ImageDraw.Draw(image)
            
            # í°íŠ¸ ì„¤ì • (ê¸°ë³¸ í°íŠ¸ ì‚¬ìš©)
            try:
                font = ImageFont.truetype("/System/Library/Fonts/Arial.ttf", 12)
                small_font = ImageFont.truetype("/System/Library/Fonts/Arial.ttf", 10)
            except:
                font = ImageFont.load_default()
                small_font = ImageFont.load_default()
            
            # OCR ê²°ê³¼ ê·¸ë¦¬ê¸°
            ocr_count = 0
            if 'ocr_data' in json_data and json_data['ocr_data']:
                ocr_count = self._draw_ocr_results(draw, json_data['ocr_data'], font, small_font)
            
            # Detection ê²°ê³¼ ê·¸ë¦¬ê¸°
            detection_count = 0
            if 'detection_data' in json_data and json_data['detection_data']:
                detection_count = self._draw_detection_results(draw, json_data['detection_data'], font)
            
            # ì´ë¯¸ì§€ë¥¼ Base64ë¡œ ì¸ì½”ë”©
            img_buffer = io.BytesIO()
            image.save(img_buffer, format='PNG', quality=95)
            img_base64 = base64.b64encode(img_buffer.getvalue()).decode()
            
            # ë¶„ì„ ê²°ê³¼ ë°˜í™˜
            result = {
                'drawing_name': d_name,
                'version': version,
                'image_base64': img_base64,
                'original_size': original_image.size,
                'resized_size': (expected_width, expected_height),
                'ocr_count': ocr_count,
                'detection_count': detection_count,
                'drawing_data': drawing_data,
                'analysis_summary': f"OCR í…ìŠ¤íŠ¸ {ocr_count}ê°œ, Detection ê°ì²´ {detection_count}ê°œ ì‹œê°í™” ì™„ë£Œ"
            }
            
            logger.info(f"ë„ë©´ ì‹œê°í™” ì™„ë£Œ: {d_name} - OCR {ocr_count}ê°œ, Detection {detection_count}ê°œ")
            return result
            
        except Exception as e:
            logger.error(f"ë„ë©´ ì‹œê°í™” ì‹¤íŒ¨: {e}")
            return None

    def _draw_ocr_results(self, draw: ImageDraw.Draw, ocr_data: Dict, font, small_font) -> int:
        """
        OCR ê²°ê³¼ë¥¼ ì´ë¯¸ì§€ì— ê·¸ë¦¬ê¸°
        
        Args:
            draw: PIL ImageDraw ê°ì²´
            ocr_data: OCR ë°ì´í„°
            font: í° í°íŠ¸
            small_font: ì‘ì€ í°íŠ¸
        
        Returns:
            ê·¸ë ¤ì§„ OCR í…ìŠ¤íŠ¸ ê°œìˆ˜
        """
        count = 0
        
        if 'images' not in ocr_data:
            return count
        
        for image_data in ocr_data['images']:
            if 'fields' not in image_data:
                continue
                
            for field in image_data['fields']:
                try:
                    # í…ìŠ¤íŠ¸ ê°€ì ¸ì˜¤ê¸°
                    infer_text = field.get('inferText', '')
                    if not infer_text:
                        continue
                    
                    # ë°”ìš´ë”© ë°•ìŠ¤ ì •ë³´ ê°€ì ¸ì˜¤ê¸°
                    bounding_poly = field.get('boundingPoly')
                    if not bounding_poly or 'vertices' not in bounding_poly:
                        continue
                    
                    vertices = bounding_poly['vertices']
                    if len(vertices) < 4:
                        continue
                    
                    # ì¢Œí‘œ ì¶”ì¶œ (ì™¼ìª½ ìœ„, ì˜¤ë¥¸ìª½ ì•„ë˜)
                    x_coords = [v.get('x', 0) for v in vertices]
                    y_coords = [v.get('y', 0) for v in vertices]
                    
                    x1, y1 = min(x_coords), min(y_coords)
                    x2, y2 = max(x_coords), max(y_coords)
                    
                    # ë°”ìš´ë”© ë°•ìŠ¤ ê·¸ë¦¬ê¸° (íŒŒë€ìƒ‰)
                    draw.rectangle([x1, y1, x2, y2], outline='blue', width=2)
                    
                    # í…ìŠ¤íŠ¸ ë ˆì´ë¸” ê·¸ë¦¬ê¸°
                    # í…ìŠ¤íŠ¸ê°€ ë„ˆë¬´ ê¸¸ë©´ ìë¥´ê¸°
                    display_text = infer_text[:20] + "..." if len(infer_text) > 20 else infer_text
                    
                    # í…ìŠ¤íŠ¸ ë°°ê²½ ê·¸ë¦¬ê¸°
                    text_bbox = draw.textbbox((x1, y1-15), display_text, font=small_font)
                    draw.rectangle(text_bbox, fill='blue')
                    draw.text((x1, y1-15), display_text, fill='white', font=small_font)
                    
                    count += 1
                    
                except Exception as e:
                    logger.warning(f"OCR í•„ë“œ ê·¸ë¦¬ê¸° ì‹¤íŒ¨: {e}")
                    continue
        
        return count

    def _draw_detection_results(self, draw: ImageDraw.Draw, detection_data: Dict, font) -> int:
        """
        Detection ê²°ê³¼ë¥¼ ì´ë¯¸ì§€ì— ê·¸ë¦¬ê¸°
        
        Args:
            draw: PIL ImageDraw ê°ì²´
            detection_data: Detection ë°ì´í„°
            font: í°íŠ¸
        
        Returns:
            ê·¸ë ¤ì§„ Detection ê°ì²´ ê°œìˆ˜
        """
        count = 0
        
        if 'detections' not in detection_data:
            return count
        
        for detection in detection_data['detections']:
            try:
                # ë¼ë²¨ ì •ë³´
                label = detection.get('label', 'Unknown')
                confidence = detection.get('confidence', 0.0)
                
                # ë°”ìš´ë”© ë°•ìŠ¤ ì •ë³´ (ì¤‘ì‹¬ì  ê¸°ë°˜)
                bbox = detection.get('boundingBox')
                if not bbox:
                    continue
                
                center_x = bbox.get('x', 0)
                center_y = bbox.get('y', 0)
                width = bbox.get('width', 0)
                height = bbox.get('height', 0)
                
                # ì‹¤ì œ ì¢Œí‘œ ê³„ì‚° (ì¤‘ì‹¬ì ì—ì„œ ì¢Œìƒë‹¨, ìš°í•˜ë‹¨ ì¢Œí‘œë¡œ)
                x1 = center_x - width / 2
                y1 = center_y - height / 2
                x2 = center_x + width / 2
                y2 = center_y + height / 2
                
                # ë°”ìš´ë”© ë°•ìŠ¤ ê·¸ë¦¬ê¸° (ë¹¨ê°„ìƒ‰)
                draw.rectangle([x1, y1, x2, y2], outline='red', width=3)
                
                # ë ˆì´ë¸”ê³¼ ì‹ ë¢°ë„ í‘œì‹œ
                label_text = f"{label} ({confidence:.2f})"
                
                # í…ìŠ¤íŠ¸ ë°°ê²½ ê·¸ë¦¬ê¸°
                text_bbox = draw.textbbox((x1, y1-20), label_text, font=font)
                draw.rectangle(text_bbox, fill='red')
                draw.text((x1, y1-20), label_text, fill='white', font=font)
                
                count += 1
                
            except Exception as e:
                logger.warning(f"Detection ê°ì²´ ê·¸ë¦¬ê¸° ì‹¤íŒ¨: {e}")
                continue
        
        return count

    def analyze_drawing_with_visualization(self, d_name: str, user_question: str = None) -> Dict:
        """
        ë„ë©´ ë¶„ì„ê³¼ ì‹œê°í™”ë¥¼ í†µí•©í•˜ì—¬ ìˆ˜í–‰
        
        Args:
            d_name: ë„ë©´ íŒŒì¼ëª…
            user_question: ì‚¬ìš©ì ì§ˆë¬¸ (ì„ íƒì‚¬í•­)
        
        Returns:
            ë¶„ì„ ê²°ê³¼ì™€ ì‹œê°í™” ì´ë¯¸ì§€ê°€ í¬í•¨ëœ ì‘ë‹µ
        """
        try:
            # ë„ë©´ ì‹œê°í™” ìˆ˜í–‰
            viz_result = self.visualize_drawing_analysis(d_name)
            
            if not viz_result:
                return {
                    'response': f"âŒ '{d_name}' ë„ë©´ì˜ ì‹œê°í™”ì— ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤.",
                    'sources': [],
                    'query_type': 'drawing_visualization',
                    'context_quality': 'none',
                    'web_search_used': False,
                    'visualization': None
                }
            
            # ë„ë©´ ë°ì´í„°ë¡œë¶€í„° í…ìŠ¤íŠ¸ ë¶„ì„
            drawing_data = viz_result['drawing_data']
            extracted_text = self.extract_text_from_drawing_data(drawing_data)
            
            # AI ë¶„ì„ í”„ë¡¬í”„íŠ¸ ìƒì„±
            analysis_prompt = f"""ë‹¹ì‹ ì€ P&ID ë„ë©´ ë¶„ì„ ì „ë¬¸ê°€ì…ë‹ˆë‹¤. ë‹¤ìŒ ë„ë©´ì„ ë¶„ì„í•˜ê³  ì‹œê°í™” ê²°ê³¼ë¥¼ ì„¤ëª…í•´ì£¼ì„¸ìš”.

**ë„ë©´ ì •ë³´:**
- íŒŒì¼ëª…: {d_name}
- ë“±ë¡ì¼: {drawing_data.get('create_date')}
- ì´ë¯¸ì§€ í¬ê¸°: {viz_result['original_size']} â†’ {viz_result['resized_size']}
- OCR í…ìŠ¤íŠ¸: {viz_result['ocr_count']}ê°œ
- Detection ê°ì²´: {viz_result['detection_count']}ê°œ

**ì¶”ì¶œëœ í…ìŠ¤íŠ¸:**
{extracted_text if extracted_text else 'í…ìŠ¤íŠ¸ ì •ë³´ ì—†ìŒ'}

**ì‹œê°í™” ê²°ê³¼:**
{viz_result['analysis_summary']}

{"**ì‚¬ìš©ì ì§ˆë¬¸:** " + user_question if user_question else ""}

**ë¶„ì„ ìš”ì²­:**
1. **ë„ë©´ ê°œìš”**: ì´ ë„ë©´ì˜ ì£¼ìš” ëª©ì ê³¼ íŠ¹ì§•
2. **OCR ë¶„ì„**: ì¶”ì¶œëœ í…ìŠ¤íŠ¸ì—ì„œ ë°œê²¬ëœ ì£¼ìš” ì •ë³´ (ê³„ì¸¡ê¸° íƒœê·¸, ì„¤ë¹„ëª… ë“±)
3. **Detection ë¶„ì„**: ê°ì§€ëœ ê°ì²´ë“¤ì˜ íŠ¹ì§•ê³¼ ë°°ì¹˜
4. **ì‹œê°í™” ì„¤ëª…**: íŒŒë€ìƒ‰ ë°•ìŠ¤(OCR)ì™€ ë¹¨ê°„ìƒ‰ ë°•ìŠ¤(Detection)ë¡œ í‘œì‹œëœ ë‚´ìš©
5. **ì¢…í•© í‰ê°€**: ë„ë©´ì˜ ì™„ì„±ë„ì™€ ì£¼ìš” íŠ¹ì§•ì 

ì‹œê°í™”ëœ ì´ë¯¸ì§€ì—ì„œ íŒŒë€ìƒ‰ ë°•ìŠ¤ëŠ” OCRë¡œ ì¶”ì¶œëœ í…ìŠ¤íŠ¸ ì˜ì—­ì´ê³ , ë¹¨ê°„ìƒ‰ ë°•ìŠ¤ëŠ” ê°ì²´ ì¸ì‹ ê²°ê³¼ì…ë‹ˆë‹¤."""

            # OpenAI API í˜¸ì¶œ
            if not self.client:
                ai_response = "OpenAI API í‚¤ê°€ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤."
            else:
                try:
                    response = self.client.chat.completions.create(
                        model="gpt-4o-mini",
                        messages=[
                            {"role": "system", "content": "ë‹¹ì‹ ì€ 20ë…„ ê²½ë ¥ì˜ P&ID ì „ë¬¸ê°€ì…ë‹ˆë‹¤. ë„ë©´ ë¶„ì„ê³¼ ì‹œê°í™” ê²°ê³¼ë¥¼ ì „ë¬¸ì ìœ¼ë¡œ í•´ì„í•©ë‹ˆë‹¤."},
                            {"role": "user", "content": analysis_prompt}
                        ],
                        temperature=0.2,
                        max_tokens=2000
                    )
                    
                    ai_response = response.choices[0].message.content
                    
                except Exception as e:
                    logger.error(f"OpenAI API í˜¸ì¶œ ì‹¤íŒ¨: {e}")
                    ai_response = f"AI ë¶„ì„ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {str(e)}"
            
            # ìµœì¢… ì‘ë‹µ êµ¬ì„±
            final_response = f"""ğŸ“Š **ë„ë©´ ì‹œê°í™” ë¶„ì„ ê²°ê³¼**

**ğŸ“„ ë„ë©´ ì •ë³´:**
- **íŒŒì¼ëª…:** {d_name}
- **ë“±ë¡ì¼:** {drawing_data.get('create_date')}
- **ë“±ë¡ì:** {drawing_data.get('user')}

**ğŸ–¼ï¸ ì‹œê°í™” ì •ë³´:**
- **ì›ë³¸ í¬ê¸°:** {viz_result['original_size'][0]} Ã— {viz_result['original_size'][1]}
- **ë¶„ì„ í¬ê¸°:** {viz_result['resized_size'][0]} Ã— {viz_result['resized_size'][1]}
- **OCR í…ìŠ¤íŠ¸:** {viz_result['ocr_count']}ê°œ (íŒŒë€ìƒ‰ ë°•ìŠ¤)
- **Detection ê°ì²´:** {viz_result['detection_count']}ê°œ (ë¹¨ê°„ìƒ‰ ë°•ìŠ¤)

---

{ai_response}

---

**ğŸ“Œ ì‹œê°í™” ë²”ë¡€:**
- ğŸ”µ **íŒŒë€ìƒ‰ ë°•ìŠ¤**: OCRë¡œ ì¶”ì¶œëœ í…ìŠ¤íŠ¸ ì˜ì—­
- ğŸ”´ **ë¹¨ê°„ìƒ‰ ë°•ìŠ¤**: AIê°€ ê°ì§€í•œ ê°ì²´ (ê³„ì¸¡ê¸°, ë°¸ë¸Œ, ë°°ê´€ ë“±)
"""
            
            # ì†ŒìŠ¤ ì •ë³´ êµ¬ì„±
            sources = [{
                'type': 'visualization',
                'icon': 'ğŸ¨',
                'source': f'ë„ë©´ ì‹œê°í™” - {d_name}',
                'score': None,
                'page': None,
                'content_preview': f"OCR {viz_result['ocr_count']}ê°œ, Detection {viz_result['detection_count']}ê°œ ì‹œê°í™”",
                'quality': 'high'
            }]
            
            return {
                'response': final_response,
                'sources': sources,
                'query_type': 'drawing_visualization',
                'context_quality': 'high',
                'web_search_used': False,
                'visualization': viz_result,
                'extracted_text_length': len(extracted_text)
            }
            
        except Exception as e:
            logger.error(f"ë„ë©´ ì‹œê°í™” ë¶„ì„ ì‹¤íŒ¨: {e}")
            return {
                'response': f"ë„ë©´ ì‹œê°í™” ë¶„ì„ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {str(e)}",
                'sources': [],
                'query_type': 'drawing_visualization',
                'context_quality': 'none',
                'web_search_used': False,
                'visualization': None
            }